\documentclass{pracamgr}  
\usepackage{lmodern} 
\usepackage[polish]{babel} 
\selectlanguage{polish} 
\usepackage{fontspec}
\usepackage{minted}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{dsfont}
\usepackage{mathrsfs}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{amsmath, amsthm, amssymb}
\usepackage[ansinew]{inputenc}
\usepackage{svg}
\usepackage{eucal}
\usepackage[mathcal]{eucal}
\usepackage[mathscr]{eucal}
\usepackage{csvsimple}
%===========================================================================
%                         Used for table border
%===========================================================================
\usepackage{booktabs}

\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{graphicx}  
\usepackage{makeidx}
\makeindex
\linespread{1.5} 
 

\makeatletter
\def\l@lstlisting#1#2{\@dottedtocline{1}{1.5em}{3em}{#1}{#2}}
\makeatother

\makeatletter
\renewcommand{\ALG@name}{Algorytm}
\makeatother
\renewcommand{\thealgorithm}{\arabic{chapter}.\arabic{algorithm}} 

\definecolor{grey}{gray}{0.9}
\definecolor{bg}{HTML}{FAFAFA}
\definecolor{darkgray}{HTML}{D5D5D5} 

\renewcommand*{\listlistingname}{Lista kodów źródłowych}
\makeatletter
\raggedbottom
\renewenvironment{minted@colorbg}[1]{
\linespread{1.0} 
\setlength{\fboxsep}{\z@}
\def\minted@bgcol{#1}
\noindent
\begin{lrbox}{\minted@bgbox}
\begin{minipage}{\linewidth}}
{\end{minipage}
\end{lrbox}%
\colorbox{\minted@bgcol}{\usebox{\minted@bgbox}}}
\makeatother

% Dane magistranta:

\author{Konrad Lisiecki}
\nralbumu{48211}
\title{Wycena Opcji przy pomocy Modeli Zmienności Stochastycznej} 
\kierunek{Finanse i rachunkowość}
\instytut{Ekonometrii}
\opiekun{dra hab. Łukasza Delonga, prof. SGH} 
\date{Warszawa 2015}   
\newtheorem{defi}{Definicja}[section]
\newtheorem{prop}{Własność}
 

%===========================================================================
%                             Bibliogrphy
%=========================================================================== 
\usepackage[style=numeric,sorting=none,defernumbers=true, backend=bibtex]{biblatex}
\addbibresource{biblio.bib}
 
%===========================================================================
%                               Listings
%===========================================================================
\renewcommand\listoflistingscaption{Spis kodów źródłowych}
\renewcommand\listingscaption{Kod źródłowy}

\usepackage{chngcntr}% http://ctan.org/pkg/chngcntr
\counterwithin{listing}{chapter}

%===========================================================================
%                           Begin of document 
%===========================================================================
\begin{document}
\maketitle

%===========================================================================
%                               Introduction
%===========================================================================
\cleardoublepage
\phantomsection
\chapter*{Streszczenie} 
\addcontentsline{toc}{chapter}{Streszczenie} \markboth{Summary}{}


Tematem pracy magisterskiej jest wycena opcji przy pomocy modeli zmienności stochastycznej. 
W standardowych modelach służących do wyceny opcji przyjmuje się (jak np. w modelu 
Blacka-Scholesa), że zmienność jest stała, niezależna od czasu. 
Jak dalekie jest to założenie od rzeczywistości pokazał chociażby ostatni kryzys 
ekonomiczny, gdzie kursy instrumentów finansowych wahały się o wiele bardziej niż w czasach
koniunktury gospodarczej. Stąd też, w bardziej ogólnych modelach służących do wyceny opcji uzmiennia 
się parametr opisujący zmienność instrumentów finansowych i uzależnia się go od czasu. 

W drugim rozdziale zostanie opisany model Hestona i sposób w jaki można go zastosować do wyceny 
opcji. Zostaną przedstawione kroki jakie należy poczynić, aby wycenić opcję przy pomocy tego modelu.
Pokazane zostaną również możliwości dalszych uogólnień modelu Hestona. 
Polegają one głównie na próbie uzależnienia od czasu tych wartości parametrów, które w 
modelu Hestona są stałe w czasie.

Trzeci rozdział jest poświęcony kalibracji modelu, czyli znalezieniu 
optymalnych wartości nieznanych parametrów modelu. Optymalna wartość jest w tym przypadku zdefiniowana
jako taka, dla której wartość opcji, wyliczonej na podstawie modelu Hestona, jest najbliższa wartości 
obserwowanej na rynku.

W czwartym rozdziale zostanie przedstawiony algorytm symulacji Monte Carlo. 
Wprowadzone zostanie pojęcie dyskretyzacji procesu stochastycznego, które jest kluczowym elementem
jeśli chodzi o dokładność i szybkość działania symulacji. 


Ostatni rozdział to już próba empirycznego zbadania zachowania modelu Hestona. Zostanie w nim 
porównana wartość opcji na indeks \textit{S\&P500} wyznaczona w oparciu o model Blacka-Scholesa i model 
Hestona.



%===========================================================================
%                               Table of contents
%===========================================================================
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Spis treści}
\tableofcontents


%===========================================================================
%                               Wprowadzenie
%===========================================================================
\chapter{Wprowadzenie}
\label{chap:introduction}
\begin{quote}

  We developed what is known a stochastic volatility model. 
  This is a model where the volatility as well as the 
  underlying asset price moves around in an unpredictable way.

\raggedleft\slshape John Hull \index{Hull, John}
\end{quote}
Niniejsza praca jest poświęcona modelom zmienności stochastycznej używanych przy wycenie opcji. 
Nasuwa się jednak pytanie, czym dokładnie są te modele? 
Jaka jest ich istota? Jaka motywacja stoi za ich powstaniem?


Bardzo zwięzłej, a zarazem trafnej odpowiedzi na te pytania udziela John Hull, 
jeden z pionierów dzisiejszych finansów ilościowych. Stwierdza on, zgodnie z przytoczonym 
powyżej cytatem, że są to modele, gdzie nie tylko cena aktywa bazowego, ale również jego zmienność, 
poruszają się w sposób nieprzewidywalny, losowy. 

W niniejszej pracy przedstawiony zostanie model Hestona, w którym zmienność nie jest wartością stałą 
oraz sposób wyznaczenia wartości opcji przy pomocy tego modelu.
Część empiryczna pracy jest z kolei próbą sprawdzenia, jak model, oraz narzędzia do jego stosowania, 
sprawdzają się w praktyce.

W dalszej części tego rozdziału, zostanie przedstawiona motywacja do rozwoju takich modeli oraz w jaki 
sposób wpływają one na dokładność analizy finansowej i efektywność rynków finansowych. 


\section{Rys historyczny} % (fold)
\label{sec:rys_historyczny}

Do lat '90 XX wieku podstawowym modelem do wyceny opcji był model Blacka-Scholesa. Opublikowany w 
1973  \cite{BlackScholes} roku artykuł, którego autorami 
byli \textbf{Fischer Black}\index{Black, Fisher} oraz \textbf{Myron Scholes}\index{Scholes, Myron},
był przełomowy dla teorii wyceny opcji.
U jego podstaw leży bardzo istotne założenie mówiące o tym, że zmienność instrumentów finansowych 
jest stała w czasie. 
Niestety, założenie to jest niezgodne z tym co możemy obserwować na rynkach finansowych. 
Można to szczególnie mocno zauważyć w czasie cyklicznie powtarzających się kryzysów finansowych.

Obserwowalna duża zmienność w czasie parametru zmienności na rynkach finansowych stała się podstawową 
motywacją wprowadzenia modeli wyceny
opcji, dla których zmienność nie jest ustalonym parametrem, a zmienną zależną od pewnych innych 
czynników. Pionierem w tym obszarze okazał się \textbf{Steven Heston}\index{Heston, Steven}, który w 
1993 opublikował pracę gdzie wprowadza nowy model wyceny opcji, w którym nie tylko proces cen 
instrumentu bazowego, ale również proces zmienności jest stochastyczny (losowy) i zależny od 
czasu \cite{Heston}. Na jego cześć, model ten w literaturze znany jest pod nazwą modelu Hestona.
 

\section{Wycena opcji na potrzeby rynków finansowych} % (fold)

Instrumenty pochodne, a w szczególności opcje, są dzisiaj bardzo ważną klasą instrumentów finansowych 
i stanowią znaczną część wartości obrotu na światowych giełdach.

Światowy rynek derywatów, który dziś jest warty około 450 mld EUR  \cite{GlobalDerMarket}, jeszcze 
około 25 lat temu był bardzo mały. Powstaje więc pytanie co wpłynęło na rozwój tego typu transakcji 
na globalnym rynku? Z punktu widzenia rynku finansowego jest jedno wytłumaczenie tego zjawiska:
instrumenty pochodne, a szczególnie opcje, pozwalają na handel przyszłym ryzykiem związanym z ruchem 
cen instrumentów bazowych. W związku z tym można wyróżnić dwa podstawowe 
zastosowania opcji: 

\begin{enumerate}
  \item jako element zarządzania ryzykiem (\textit{ang. hedging}),
  \item jako inwestycja.
\end{enumerate}

Pierwsze zastosowanie odnosi się do wymiany lub ograniczenia ryzyka rynkowego. Przedsiębiorstwa i 
instytucje finansowe używają opcji do 
ochrony przed niechcianymi, gwałtownymi ruchami instrumentów bazowych takich jak surowce, stopy 
procentowe czy kursy akcji. Wpływa to na 
\textbf{wygładzenie przepływów pieniężnych} (\textit{ang. cash flows}) w obrębie przedsiębiorstwa, co 
ma znaczenie w kontekście stabilności działalności 
podmiotu gospodarczego. Dla przykładu, 92\% spośród 500 największych przedsiębiorstw świata ogranicza 
ryzyko przy pomocy derywatów  \cite{GlobalDerMarket}.


Transakcje na rynku instrumentów pochodnych są szczególnie ważne z punktu widzenia 
ograniczenia \textbf{ryzyka walutowego}. Na rysunku \ref{fig:currencyRisk} przedstawiono kurs dolara 
amerykańskiego w stosunku do rosyjskiego rubla na przestrzeni ostatnich 20 lat.
Można na nim odnotować gwałtowne wahania kursu, które dla wielu przedsiębiorstw, nie stosujących 
instrumentów pochodnych w celu ograniczenia ryzyka walutowego, może oznaczać bardzo szybkie 
bankructwo. 
\begin{figure}
  \centering  
  \includegraphics[width=0.80\textwidth]{../output/figures/currencyUSDRUB.pdf}
  \caption{Kurs walutowy rosyjskiego rubla w stosunku do dolara amerykańskiego.}\label{fig:currencyRisk}
\end{figure} 
 
Instrumenty pochodne mogą być również postrzegane przez uczestników rynku jako inwestycja. 
Różnią się one od inwestycji w instrumenty bazowe w tym sensie, że można w nie inwestować bez ich 
fizycznego zakupu.
Ponadto stwarzają one możliwość inwestycji w instrumenty, których po prostu nie można kupić 
bezpośrednio. Dobrym na to przykładem są derywaty pogodowe, które umożliwiają ubezpieczenie przed 
spadkiem temperatury poniżej określonego poziomu.
Pozwalają one również inwestorom na zajęcie pozycji w danym instrumencie finansowym nawet wtedy, gdy 
spodziewają się spadku ich wartości. W żargonie inwestycyjnym zajęcie takiej pozycji jest znane pod 
nazwą zajęcia \textbf{pozycji krótkiej} (\textit{ang. short position}).


\section{Wycena opcji na potrzeby rachunkowości}
\label{sec:aspekty_finansowe}

Jedną z nadrzędnych zasad rachunkowości jest \textbf{zasada prawdziwego i rzetelnego obrazu}. Oznacza 
ona, że rachunkowość musi pokazywać rzetelny, czyli prawdziwy i wiarygodny
obraz stanu majątkowego danej spółki. Zewidencjonowana cena instrumentów pochodnych, a w 
szczególności opcji, powinna więc odzwierciedlać ich \textbf{rzeczywistą 
(godziwą) wartość} (\textit{ang. fair value}) na moment bilansowy. W praktyce oznacza to, że 
zaawansowane modele wyceny opcji można zastosować w dwóch działach rachunkowości: rachunkowości 
sprawozdawczej oraz rachunkowości zarządczej.


\subsection{Rachunkowość sprawozdawcza} % (fold)
\label{sub:rachunkowosc_sprawozdawcza}
Pierwszym źródłem zastosowania zaawansowanych form wyceny opcji jest rachunkowość sprawozdawcza.
Opcje będące w posiadaniu przedsiębiorstwa, jako aktywa finansowe, są integralnym składnikiem każdego 
sprawozdania finansowego. Na koniec 
każdego roku sprawozdawczego istnieje potrzeba określenia ich wartości w celach sprawozdawczych.
\textbf{Międzynarodowy Standard Sprawozdawczości Finansowej MSSR 13} 
(\textit{ang. IFRS\index{IFRS}, International Financial Reporting Standard}) 
nie określa dokładnie w jaki sposób takie opcje mają być wycenione. 
Określa jednak, że jednostka powinna użyć takiej metody, która odzwierciedla
rzeczywistą  wartość instrumentu finansowego na dany moment. MSSR 13 wyróżnia podstawowe podejścia 
do ich wyceny \cite{IFRS2013}:
\begin{enumerate}
  \item podejście dochodowe\index{Podejście dochodowe} (\textit{ang. income approach}),
  \item podejście rynkowe\index{Podejście rynkowe} (\textit{ang. market approach}),
  \item podejście kosztowe\index{Podejście kosztowe} (\textit{ang. cost approach}).
\end{enumerate}
Pierwsze z nich, \textbf{podejście dochodowe}, określa wartość godziwą instrumentu finansowego na 
podstawie bieżących oczekiwań rynkowych co do wartości 
przyszłych przepływów pieniężnych i zdyskontowania ich na moment bieżący. Najbardziej powszechnymi 
modelami w tym podejściu są modele Blacka-Scholesa 
oraz model dwumianowy  \cite{IFRS2013}. W ostatnich latach jednak, w dobie postępu technologicznego, 
coraz istotniejszą rolę odgrywają bardziej zaawansowane metody probabilistyczne
(jak będące tematem tej pracy metody bazujące na modelowaniu zmienności przy pomocy stochastycznych 
równań różniczkowych) oraz symulacje Monte Carlo  \cite{FairValue2010}.  


\subsection{Rachunkowość zarządcza} % (fold)
\label{sub:RachunkowoscZarzadcza}
Kolejnym źródłem zastosowania bardziej zaawansowanych form wyceny instrumentów finansowych jest 
rachunkowość zarządcza. 
W przypadku wielu opcji niepłynnych, z wbudowaną możliwością wcześniejszego wykupu, standardy 
rachunkowości sprawozdawczej dopuszczają
\textbf{wycenę wg. zamortyzowanego kosztu nabycia} (\textit{ang. cost approach}). Organy zarządcze 
przedsiębiorstwa potrzebują jednak znać jak najbardziej dokładną sytuację księgowo-finansową 
przedsiębiorstwa, aby móc podejmować trafne decyzje bieżące i rozwojowe z punktu widzenia spółki. 
Wycena opcji przy pomocy metod użytych w tej pracy, może dać bardziej dokładną wycenę instrumentów 
finansowych, a co za tym idzie, lepszy obraz kondycji spółki dla osób zarządzających.  



\section{Model Blacka-Scholesa\index{Model Blacka-Scholesa}}

Poprzednie podrozdziały opisywały elementy rzeczywistości ekonomicznej na który istotny wpływ może 
mieć przyjęta metodologia wyceny opcji. W tym pokażemy najbardziej powszechny model do wyceny opcji, 
model Blacka-Scholesa. 
\subsection{Klasyczny model Blacka-Scholesa} % (fold)
\label{sub:subsection_name}

Rozważmy następujący model przedstawiający ewolucję ceny aktywa
bazowego w czasie oraz obligacji, jako instrumentu finansowego pozbawionego ryzyka:
\begin{equation}
  \label{eq:asset}
  dS_t = \mu S_t dt + \sigma S_t d W_t 
\end{equation}

\begin{equation}
  \label{eq:nonRiskAsset}
  dB_t = r B_t dt, B_0 = 1, S_0 = 1
\end{equation}
gdzie:
\begin{enumerate}
  \item $S_t$ - cena aktywa bazowego
  \item $B_t$ - cena aktywa pozbawionego ryzyka
  \item $\mu$ - dryft ceny aktywa bazowego
  \item $\sigma$ - zmienność aktywa bazowego
  \item $W_t$ - proces Wienera
\end{enumerate}


Model ten znany jest pod nazwą \textbf{modelu Blacka-Scholesa} i jest fundamentalnym 
narzędziem do wyceny opcji. Równanie \ref{eq:nonRiskAsset}  jest istotną częścią modelu, ponieważ 
określa miarę w jakiej wyceniamy daną opcję. W zdecydowanej większości przypadków jest to miara 
neutralna względem ryzyka (miara martyngałowa\index{Miara martyngałowa}). 
Rozwiązując równania (\ref{eq:asset}) oraz (\ref{eq:nonRiskAsset}) można wyznaczyć:
\begin{equation}
B_t = e^{rt}
\end{equation}
co odpowiada procesowi kapitalizacji stopą równej stopie oprocentowania aktywa wolnego od ryzyka.

Zgodnie z teorią wyceny opcji, jej wypłata $v$ w mierze neutralnej względem ryzyka (na moment $t = 0$) 
jest równa:

\begin{equation}
\label{eq:discounting}
 \frac{\mathbf{E}[v(S_T)]}{e^{rT}}
\end{equation}
gdzie dynamikę cen aktywa bazowego opisuje następujący proces opisany w równaniu (\ref{eq:asset}).

Jak więc wynika z tego równania cenę opcji określamy jako zdyskontowaną na moment zerowy wartość
oczekiwaną z wypłat opcji w momencie jej wygaśnięcia. 

\subsection{Założenia modelu Blacka-Scholesa} % (fold)
\label{sub:zalozenia_modelu_blacka_scholesa}

Model Blacka-Scholesa należy do najbardziej popularnych, a zarazem najprostszych modeli do wyceny 
opcji. Podczas gdy jego prostota jest jedną z jego największych zalet, to posiada on wiele założeń,
które nie przystają do rzeczywistości rynkowej. Pierwsza grupa to założenia dotyczące aktywów:
\begin{enumerate}
\item cena aktywów bazowych ma rozkład lognormalny,
\item zmienność aktywów bazowych jest stała i znana z góry,
\item akcje nie wypłacają dywidend.
\end{enumerate}
Z kolei druga grupa założeń odnosi się do rynku na którym dane aktywa występują.
\begin{enumerate}
\item na rynku nie ma możliwości osiągnięcia ponadnormatywnego zysku bez ryzyka (brak możliwości arbitrażu),
\item nie ma kosztów transakcyjnych,
\item stopa procentowa na rynku jest stała i znana z góry.
\end{enumerate}

Wszystkie te założenia sprawiają, że model Blacka-Scholesa, mimo, że pozwala na wyznaczenie ceny
 opcji w postaci analitycznej, może nieprecyzyjnie wycenić wartość takiej opcji.
  
\subsection{Zmienność implikowana} % (fold)
\label{sub:zmienno_implikowana} 
Kalibracja jest jednym z najważniejszych elementów procesu wyceny opcji.
W przypadku modelu Blacka-Scholesa jedynym nieobserwowalnym parametrem jest zmienność $\sigma$ (
współczynnik dyfuzji). Można go wyznaczyć na jeden z dwóch sposobów:
\begin{enumerate}
  \item zmienność historyczna,
  \item zmienność implikowana.
\end{enumerate}

Zmienność historyczna jest średnią (ważoną) zmienności zaobserwowanej na rynku w czasie 
poprzedzającym moment wyceny.

Szczególnie interesującym przypadkiem jest jednak zmienność implikowana, ponieważ 
wyraża ona \textit{"przewidywania rynku"} co do wartości zmienności danego aktywa bazowego. 
Można ją w prosty sposób obliczyć przy użyciu analitycznego \textbf{wzoru Blacka-Scholesa} na 
wycenę opcji, który da się przedstawić jako:

\begin{equation}
  \label{eq:impliedVol}
  C_{obs} = C(S_0, T, K, \sigma_{imp}, r)
\end{equation}
Jak widać, wiedząc jaka jest cena opcji na podstawie danych rynkowych, równanie (\ref{eq:impliedVol}) 
staje się równaniem z jedną niewiadomą, z którego możemy wyliczyć $\sigma_{imp}$.

W przypadku bardziej skomplikowanych modeli, nieznanych parametrów może być dużo więcej. Wtedy też 
stosuje się bardziej zaawansowane techniki kalibracyjne, co będzie tematyką 
rozdziału \ref{chap:chapterModelCalibration}.
  % \autoref - ok but it uses the english name of chapter

\subsection{Wycena opcji europejskiej} % (fold)
\label{sub:subsection_name}
 
Mając wartości wszystkich parametrów modelu Blacka-Scholesa jesteśmy w stanie przystąpić
do wyliczenia wartości opcji. Można wyznaczyć wartość opcji europejskiej dla 
strony kupującej (\textit{and. long call option}). Wypłata ta wynosi:

\begin{equation}
  v(S_T) = max(S_T-K, 0)
\end{equation}

W powyższym wzorze $K$, czyli cena wykupu opcji jest parametrem, stąd też, aby 
wyliczyć wartość opcji należy obliczyć wartość instrumentu bazowego w momencie wygaśnięcia opcji.

W tym celu należy rozwiązać stochastyczne równanie różniczkowe (\ref{eq:asset}). W modelu Blacka-Scholesa
można pokazać, że wartość ceny aktywa bazowego na moment wygaśnięcia opcji możemy wyznaczyć przy pomocy
następującego wzoru:
\begin{equation}
\label{eq:closedFormBlack} 
  S_T = S_0 e^{(r - \frac{1}{2} \sigma^2)T+\sigma \sqrt{T} X}
\end{equation}
gdzie: $X \sim N(0,1)$.
Fragment wzoru postaci $\frac{1}{2} \sigma^2 T$ znany jest natomiast pod 
nazwą \textbf{poprawki Ito}\index{Poprawka Ito} (\textit{ang. Ito correction}).
Odpowiada on za przejście z modelu deterministycznego, opisywanego przez równania różniczkowe
zwyczajne, do modelu losowego, które opisują stochastyczne równania różniczkowe.

W końcu, aby uzyskać cenę opcji na dany moment, stosujemy wzór (\ref{eq:closedFormBlack}). Otrzymujemy
\begin{equation}
  C = \frac{\mathbf{E}[v(S_0 e^{(r - \frac{1}{2} \sigma^2)T+\sigma \sqrt{T} X})]}{e^{rT}}
\end{equation}
gdzie:
\begin{itemize}
  \item $X \sim N(0,1)$,
  \item $C$ oznacza wartość opcji na moment zerowy $t = 0$.
\end{itemize}




\section{Stosowane podejścia w procesie wyceny opcji} % (fold)
\label{sec:}

Istnieją dwa główne sposoby używane podczas wyceny opcji: skorzystanie ze wzorów analitycznych 
lub przeprowadzenie symulacji. O ile dla modelu Blacka-Scholesa rozwiązanie analityczne istnieje, 
to dla modeli o bardziej złożonych formułach, takich jak model Hestona, takich rozwiązań nie ma. 

Dlatego też o wiele bardziej uniwersalnym rozwiązaniem problemu wyceny opcji jest podejście symulacyjne.
Niezależnie od rodzaju opcji, czy też modelu opisującego dynamikę cen aktywa bazowego, można 
wyróżnić podobne etapy symulacji. Zaliczamy do nich:
\begin{enumerate}
  \item Kalibracja modelu,
  \item Generowanie zmiennych losowych o ustalonym rozkładzie,
  \item Wyznaczenie wartości zmiennych losowych opisujących realizacje procesu stochastycznego,
  \item Estymacja wartości oczekiwanej wypłaty.
\end{enumerate}

Kalibracja modelu jest tematem rozdziału \ref{chap:chapterModelCalibration}, natomiast pozostałe 
elementy będą przedstawione w rozdziale nr \ref{chap:monteCarlo}, poświęconym metodzie Monte Carlo.





%===========================================================================
%
%                               Model Hestona
%
%===========================================================================
\chapter{Model Hestona\index{Model Hestona}}
\label{chap:hestonModel}

Obecnie jednym z najpopularniejszych modeli do wyceny opcji jest przedstawiony 
w rozdziale \ref{chap:introduction} model Blacka-Scholsa. Ceniony jest 
on ze względu na prostotę oraz wygodę użycia, kosztem jednak wielu upraszczających założeń. 
Jedno z nich, założenie o stałości zmienności jest modyfikowane w modelu Hestona, który jest 
tematem tego rozdziału.


\section{Motywacja} 
Jak zostało powiedziane we wstępie do niniejszego rozdziału, podstawowym modelem do wyceny opcji jest 
model Blacka-Scholesa.
Możemy w nim wyprowadzić wzór na cenę opcji europejskiej w postaci analitycznej. 

Jednym z założeń modelu Blacka-Scholesa jest założenie o stałej zmienności instrumentu bazowego, 
które okazuje się być nieprawdziwe w rzeczywistym świecie. Świadczy o tym chociażby
wykres nr \ref{fig:vix}, na którym wyraźnie widać duże wahania zmienność ceny instrumentu bazowego.
Jednym z pomysłów na
obejście tego problemu jest uzmiennienie stałej wartości wariancji w tym modelu. Dopuszczamy w ten 
sposób, aby dla dowolnego czasu parametr ten przyjmował różną wartość. Można to zrobić np. poprzez 
nadanie cech losowych parametrowi zmienności. 
W takim przypadku nie tylko proces ceny akcji byłby procesem 
stochastycznym, ale także sama zmienność byłaby definiowana przy użyciu procesu stochastycznego. 
Tak powstała nowa klasa modeli wyceny opcji o nazwie \textbf{modele zmienności stochastycznej} 
(\textit{ang. stochastic volatility models}), której podstawowym 
przedstawicielem jest model Hestona.



\begin{figure}
  \centering  
  \includegraphics[width=0.80\textwidth]{../output/figures/volatilitySANDP.pdf}
  \caption{Zmieność w czasie indeksu S\&P}\label{fig:vix}
\end{figure} 

\section{Model Hestona}
Jak wspomniano w poprzednim rozdziale, model Hestona eliminuje podstawową wadę modelu Blacka-Scholesa 
jakim jest założenie o stałej zmienności w czasie.
W tym celu zmienność uzależniono od dodatkowego procesu losowego. W 
przypadku modelu Hestona współczynnik zmienności może być opisany następującym równaniem:
\begin{equation}
\label{eq:cir}
dv_t  = \kappa (\theta  - v_t)dt + \varepsilon \sqrt{v_t} dW_t^v 
\end{equation}

Proces $v$ zdefiniowany przy pomocy (\ref{eq:cir}) posiada 
\textbf{\textit{własność powrotu do średniej długoterminowej}} (\textit{ang. mean-reversion}). 
Jeżeli byśmy założyli, że zmienność nie ma własności powrotu do średniej, obserwowalibyśmy 
znaczną część aktywów ze zmiennością bardzo gwałtownie rosnącą lub będącą blisko zera.
Z tego powodu, gdy założymy że proces spełnia \textbf{warunek Fellera\index{Warunek Fellera}}:
\begin{equation}
2 \kappa \theta > \varepsilon^2
\end{equation}
proces jest ściśle dodatni \cite{TheLittleHestonTrap}. Zmienność wtedy będzie zawsze wartością większą
od zera, co jest zgodne z jej definicją.

Mając równanie opisujące proces zmienności można już przedstawić model Hestona, który ma postać:

\begin{equation}
\label{eq:heston1}
dS(t)  = r S(t) dt + \sqrt{v(t)} S(t) dW^S(t)
\end{equation}
gdzie wariancja $v_t$ jest opisana przez następujące równanie: 

\begin{equation}
\label{eq:heston2}
dv(t)  = \kappa (\theta - v(t))dt + \varepsilon \sqrt{v(t)} dW^v(t) 
\end{equation}
Procesy $dW^v(t)$ oraz $dW^S(t)$ są standardowymi procesami 
Wienera\index{Proces Wienera} i są 
skorelowane:

\begin{equation}
Cov[dW^S(t), dW^v(t)] = \rho dt 
\end{equation}
gdzie:

\begin{enumerate}
\item $r$ oznacza dryft (\textit{ang. drift}) ceny aktywa bazowego 
\item $\theta$ oznacza długoterminową wartość oczekiwaną $v_t$
\item $\kappa$ jest współczynnikiem szybkości powrotu do średniej (\textit{ang. rate of mean-reversion})
\item $\varepsilon$ oznacza zmienność zmienności procesu $v_t$
\end{enumerate}

W przedstawionym modelu występuje równanie $Cov[dW^S(t), dW^v(t)] = \rho dt $. Mówi ono o tym, że 
dwa procesy błądzenia losowego są ze sobą skorelowane przy pomocy stałego 
współczynnika korelacji $\rho$.
To założenie jest zgodne z rzeczywistością. Często możemy na rynkach finansowych zaobserwować 
następującą sekwencję zdarzeń: gdy cena rośnie gwałtownie w górę, zwiększa się zmienność, 
natomiast w okresach spokoju zmienność jest na relatywnie niskim poziomie.

Niestety, w odróżnieniu od modelu Blacka-Scholsa, dla modelu Hestona nie istnieje pełne rozwiązanie 
analitycznie (istnieje tylko częściowe rozwiązanie analityczne). Wobec tego, aby 
wyliczyć wartość opcji, należy się posłużyć metodami numerycznymi.

\section{Aplikacja lematu Ito dla modelu Hestona}

Pracując z szeregami czasowymi często łatwiej jest operować na 
logarytmach procesu bazowego, czyli $\ln S(t)$.
Podstawowym narzędziem używanym w wykonywaniu takich transformacji jest lemat Ito.

Procesy stochastyczne opisane równaniami (\ref{eq:heston1}) i (\ref{eq:heston2}) są tak 
zwanymi \textbf{procesami Ito}
(\textit{ang. Ito process}), które ogólnie dają się przedstawić w 
następującej formie:
\begin{equation}
  dx = a(x,t) dt + b(x,t) dz
\end{equation}
gdzie o zmiennej $a$ można myśleć jako o współczynniku opisującym
wielkości wzrostu, natomiast 
o zmiennej $b$ jako o współczynniku definiującym jak duża jest losowość w danym 
modelu.

Dla procesów zdefiniowanych zgodnie z tym równaniem, możemy 
stosować \textbf{lemat Ito} (\textit{ang. Ito lemma}). Możemy na niego patrzeć 
jako stochastyczny odpowiednik reguły łańcuchowej (\textit{ang. chaining rule}) znanej z 
klasycznego rachunku różniczkowego. 
Po zastosowaniu lematu Ito dla $S(t)$ otrzymujemy układ równań z logarytmem aktywa bazowego $\ln S(t)$:
\begin{subequations}
\begin{align}
d \ln S(t) &= \left( r - \frac{1}{2} v(t) \right) dt 
              + \sqrt{v(t)} SdW^S(t) \label{eq:HestonlnS} \\
dv(t)      &= \kappa (\theta - v(t))dt + \varepsilon 
              \sqrt{v(t)} dW^v(t)  \label{eq:HestonlnY}
\end{align} 
\end{subequations}
Aplikując do równania (\ref{eq:HestonlnS}) \textbf{dekompozycję Cholesky'ego} można
otrzymać następującą zależność:
\begin{equation}
  \ln S(t + \Delta) = \ln S(t) + \left( r - \frac{1}{2} v(t) \right) dt 
              + \rho \sqrt{v(t)} dW^v(t) + \sqrt{1 - \rho^2} \sqrt{v(t)} dW(t)
\end{equation}
Natomiast drugie równanie (\ref{eq:HestonlnY}) można przedstawić jako:
\begin{equation}
  v(t + \Delta)      = v(t) + \int_t^{t+\Delta} \kappa 
                        (\theta - v(u))du + \varepsilon 
                        \int_t^{t+\Delta}  \sqrt{v(t)} dW^v(u) du 
\end{equation}
Co można przekształcić do następującej postaci:
\begin{equation}
  \int_t^{t+\Delta}  \sqrt{v(t)} dW^v(u) du  = \varepsilon^{-1} \left(v(t+\Delta) 
  - v(t) - \kappa \theta \Delta + \kappa \int_t^{t+\Delta}  v(u) du \right)
\end{equation}
Podstawiając to równanie do równania (\ref{eq:HestonlnS}) otrzymujemy:
\begin{equation}
\begin{aligned}
\label{eq:HestonLnSDiscretization}
\ln S(t + \Delta) = & \ln S(t) + r \Delta + \frac{\rho}{\varepsilon} (v(t + \Delta)  - v(t) - \kappa \theta \Delta) + \\
& \Big( \frac{\kappa \rho}{\varepsilon} - \frac{1}{2} \Big)
\int_t^{t+\Delta} v(u) du + \sqrt{1-\rho^2} \int_t^{t+\Delta} \sqrt{v(u)}dW(u)
\end{aligned}
\end{equation}

Powyższe równanie przedstawia dokładny wzór na wartość aktywa 
bazowego $\ln S(t + \Delta) $ mając daną wartość $\ln S(t)$.
Jedyną trudnością w wyznaczeniu wartości aktywa bazowego w momencie
$t + \Delta$ stanowią dwie całki, które muszą zostać wyzanczone przy 
pomocy metod numerycznych. 

\section{Wzór opisujący cenę opcji w modelu Hestona}

W modelu Hestona można wyznaczyć cenę dla europejskiej opcji \textit{call} na moment t, 
gdzie $t \in [0, T]$. Można ją zdefiniować, w sposób analogiczny do modelu Blacka-Scholesa, jako 
\cite{Heston}:

\begin{equation}
\label{eq:HestonCharacteristicFirst}
  C(S, v, t) = SP_1 -K e^{-r(T-t)} P_2
\end{equation}
gdzie:

\begin{equation}
\label{eq:HestonProb}
  P_j (x, v, T; ln[K]) = \frac{1}{2} + \frac{1}{\pi} \int_{0}^{\infty} Re \bigg[ \frac{e^{-i \cdot \phi ln[K]} f_j(x, v, T; \phi) }{i \phi} d \phi \bigg]
\end{equation}

\begin{equation}
  x = ln(S_t)
\end{equation}
Funkcje charakterystyczne mają postać: 

\begin{equation}
\label{eq:HestonCharacteristic}
  \begin{aligned}
f_j(x, v, T; \phi) &= e^{C_j(T-t; \phi) + D_j(T-t; \phi)v + i \phi x} \\
C_j (\tau; \phi)     &= r \phi i \tau + \frac{a}{\sigma^2} \bigg\{ (b_j - \rho \sigma \phi i + d) \tau - 2 \cdot ln \bigg[ \frac{1 - ge^{dr}}{1-g} \bigg] \bigg\} \\
D_j (r; \phi)        &= \frac{b_j- \rho \sigma \phi i + d}{\sigma^2} \bigg[ \frac{1 - e^{d_j \tau}}{1 - g_je^{d\tau}} \bigg]   \\
g_j                &= \frac{b_j - \rho \sigma \phi i + d}{b_j - \rho \sigma \phi i - d} \\
d_j                &= \sqrt{(\rho \sigma \phi i  - b_j)^2 - \sigma^2(2 u_j \phi  i  - \phi^2)}.
  \end{aligned}
\end{equation}
gdzie:
\begin{itemize}
  \item  $ u_1 = \frac{1}{2}$
  \item  $ u_2 = -\frac{1}{2}$
  \item  $ a = \kappa * \theta$
  \item  $ b_1 = \kappa + \lambda - \rho * \sigma$
  \item  $ b_2 = \kappa + \lambda$
\end{itemize}
dla: $j = 1,2$.

Przedstawione powyżej równania (\ref{eq:HestonProb}) oraz 
(\ref{eq:HestonCharacteristic}) będą użyte podczas kalibracji modelu. Należy jednak zaznaczyć, że 
w literaturze istnieją inne postacie analityczne ceny $C(S, v, t)$, które są bardziej wydajne 
obliczeniowo. 
Wiąże się to z faktem, że np. w wyrażeniu (\ref{eq:HestonProb}) występują dwie funkcje podcałkowe. 
Można pokazać, że równanie to da się przedstawić przy pomocy tylko jednej całki.

\subsection{Uproszczony wzór ceny opcji w modelu Hestona} % (fold)
\label{sec:numeryczne_wyznaczenie_warto_ci_funkcji_charakterystycznej}

Ważnym elementem podczas kalibracji modelu jest jak najszybsze wyznaczenie ceny opcji dla danego
zestawu parametrów. 
Jedną z metod używanych w tym celu jest całkowanie funkcji występującej we wzorze na funkcję
charakterystyczną (\textit{ang. Direct Integration}). Polega ona na wyznaczeniu całki przy pomocy
numerycznej kwadratury, jak np. kwadratury Gaussa\index{Kwadratura Gaussa}. Można także zastosować
inną postać funkcji charakterystycznej, wyznaczoną przez Attariego \cite{Attari}\index{Attari,
Mukarram}, która jest bardziej efektywną metodą do jej obliczenia:
\begin{equation}
\label{eq:AttariCharacteristicFirst}
\begin{aligned}
  C(S_0, T, K) = S_0 &- \frac{1}{2} e^{-rT}K  \\ 
  &- e^{-rT} K 
  \left( \frac{1}{\pi} \int_0^{+\infty} Z d\omega \right)
    \end{aligned}
\end{equation}
gdzie:

\begin{equation}
\label{eq:AttariCharacteristic}
  Z = \frac{
(Re(\phi (\omega) )
+\frac{Im(\phi (\omega)}{\omega}
cos(\omega l (K)) +
(Im(\phi (\omega) - \frac{Re(\phi (\omega)}{\omega}
sin(\omega l (K))
}{1 + \omega^2}
\end{equation}
Jedynym ograniczeniem powyższego układu jest fakt, że równania 
(\ref{eq:HestonCharacteristicFirst}) - (\ref{eq:HestonCharacteristic}) pozwalają wyznaczyć wartość opcji w 
dowolnym momencie jej trwania, natomiast równania 
(\ref{eq:AttariCharacteristicFirst}) - (\ref{eq:AttariCharacteristic}) pozwalają wycenić 
opcję tylko na moment zerowy.


\section{Współczynniki greckie\index{Współczynniki greckie}}

Z punktu widzenia uczestnika rynku finansowego, cena jest jedną z dwóch najważniejszych 
właściwości opcji. Drugą bardzo istotną kwestią jest sprawdzenie wrażliwości opcji na jednostkowe 
zmiany poszczególnych parametrów opcji.
Definiuje się więc pięć podstawowych współczynników, znanych w literaturze pod 
nazwą \textbf{współczynników greckich}.
Zaliczamy do nich \cite{Hull}:
\begin{enumerate}
  \item $\Delta$ (delta)
  \item $\Gamma$ (gamma)
  \item $\Theta$ (theta)
  \item $v$ (vega)
  \item $\rho$ (rho)
\end{enumerate}
 

Pierwszy ze współczynników, \textbf{Delta} $\Delta$, odpowiada na pytanie w jaki 
sposób zmieni się cena opcji w odpowiedzi na
jednostkową zmianę instrumentu bazowego:
\begin{equation}
  \Delta = \frac{\delta V}{\delta S}
\end{equation} 
Kolejny, \textbf{Gamma} $\Gamma$, definiuje wrażliwość delty na 
jednostkową zmianę ceny instrumentu bazowego:
\begin{equation}
  \Gamma = \frac{\delta \Delta}{\delta S} = \frac{\delta^2 V}{\delta^2 S}
\end{equation}
\textbf{Theta} $\Theta$, trzeci ze współczynników określa tak 
zwaną \textbf{wartość czasową opcji} (ang. option time value).
Opisuje go poniższy wzór:
\begin{equation}
  \Theta = \frac{\delta V}{\delta \tau}
\end{equation}
Przedostatni współczynnik grecki nosi nazwę \textbf{Vega} $v$ i określa wrażliwość wartości 
opcji na jednostką zmianę poziomu
zmienności:
\begin{equation}
  v = \frac{\delta V}{\delta v}
\end{equation}
Ostatni wskaźnik \textbf{Rho} $\rho$ wskazuje na wrażliwość ceny na wahania stopy procentowej:
\begin{equation}
  \rho = \frac{\delta V}{\delta r}
\end{equation}
Należy zauważyć, że wzory analityczne wyznaczające wartość współczynników greckich nie zawsze istnieją. 
Okazuje się, że albo funkcja wypłaty opcji jest zbyt skomplikowana, albo sam model jest zbyt 
skomplikowany. Często też obydwa warunki występują jednocześnie. 

Współczynniki greckie są bardzo ważnymi narzędziami 
do zabezpieczenia (\textit{ang. hedging}\index{Hedging}) ryzyka 
związanego z inwestycją w instrumenty pochodne.
Do wyznaczenia wartości tych współczynników używa się metod Monte Carlo. Wynika to z faktu, 
że niemożliwe jest uzyskanie dla nich wzoru analitycznego, 
zwłaszcza dla bardziej skomplikowanych modeli jak model Hestona.

\section{Rozszerzenia modelu Hestona}

Model Hestona uogólnia założenie o stałości zmienności w czasie. 
Jednak pozostałe parametry wciąż pozostają na niezmienionym poziomie
co daje możliwość uzależnienia w czasie kolejnych stałych w modelu.
Ponadto, również wariancję w modelu Hestona można uzależnić nie tylko 
od jednego, ale od wielu procesów zmienności (\textit{ang. Multifactor Heston Models}).

Kolejną możliwością uogólnienia modelu Hestona to wprowadzenie do modeli zmienności stochastycznej
\textbf{skoków} (\textit{ang. stochastic volatility models with jumps})
Tego typu modele tworzą odrębną klasę modeli, a procesem, który najczęściej modeluje właściwość
skoków w tego typu modelach jest proces Poissona.

Celem tego rozdziału jest tylko zasygnalizowanie możliwych rozszerzeń modelu Hestona.
Mogą być one jednak zaimplementowane przy pomocy zaprojektowanego w tej pracy modułu 
do wyliczenia ceny opcji w oparciu o model Hestona. 

\subsection{Dwuczynnikowy model Hestona} % (fold)
\label{sec:modelDwuczynnikowy}
Model dwuczynnikowy Hestona został w 2009 zaproponowany prze
Petera Christoffersena \index{Christoffersen, Peter} \cite{Christoffersen}.
Opisuje go następujący układ równań:

\begin{equation}
dS_t  = r S_t dt + \sqrt{V_1} S dW_1 + \sqrt{V_2} S dW_2
\end{equation} 

\begin{equation}
dV_1  = (a_1 - b_1 V_1)dt + \sigma_1 \sqrt{V_1} dW_3 
\end{equation}

\begin{equation}
dV_2  = (a_2 - b_2 V_2)dt + \sigma_2 \sqrt{V_2} dW_4 
\end{equation}

W modelu tym zmienna $W_1$ jest skorelowana z $W_3$ na poziomie korelacji $\rho_1$, natomiast
zmienna $W_2$ z $W_4$ jest skorelowana na poziomie $\rho_2$. Ponadto, $W_1$ oraz $W_2$ są ze sobą 
nieskorelowane. Z tego względu (właściwość
liniowości wariancji dla zmiennych losowych o kowariancji równej $0$) wariancja stopy zwrotu z aktywa
bazowego jest sumą wariancji:

\begin{equation}
  Var_t[dS/S] = (V_1 + V_2)dt = Vdt
\end{equation}

Jak wynika z powyższych wzorów cena akcji instrumentu bazowego zależy teraz nie od jednego, a od 
dwóch procesów zmienności.
Jednym z powodów dla którego chcielibyśmy wprowadzać dodatkowe zmienne jest fakt, że model
Hestona nie zawsze jest w stanie dostosować się do `uśmiechu zmienności'  implikowanej, w 
szczególności dla krótkich okresów  \cite{HestonExtensions}.


\subsection{Modele zmienności stochastycznej ze skokami} % (fold)
\label{sec:modele_zmienno_ci_stochastycznej_ze_skokami}
 
Kolejnym modelem, który rozszerza model Hestona jest model zmienności stochastycznej ze skokami.

Jest wiele powodów wprowadzenia skoków do równania modelującego cenę aktywa bazowego, a wśród nich 
możemy wymienić `grube ogony' rozkładu stóp zwrotu. Zgodnie z danymi empirycznymi ogony rozkładu stóp 
zwrotu aktywa bazowego są grubsze od tych występujących w rozkładzie normalnym.

Kolejną przyczyną wprowadzenia skoków do modelu Hestona jest kształt płaszczyzny zmienności implikowanej
(\textit{ang. volatility surface}) dla opcji o krótkim terminie do wykupu. W rzeczywistości ma ona 
bardziej skośny kształt niż to wynika z danych wygenerowanych przez model Hestona. 
Bates \cite{Bates} rozszerzył więc model Hestona o dodatkowy element, który ma niwelować opisaną wadę.

Model ten różni się od modelu Hestona tylko składnikiem definiującym skoki, jednak dla
porządku podajemy jego pełną definincję:
\begin{equation}
dS_t  = \mu S_t dt + \sqrt{v_t} S_t dW^S_t + S_{t-} Y_t dN_t^S.
\end{equation}
Wariancję $v_t$ opisuje równanie: 

\begin{equation}
dv_t  = \kappa (\theta - v_t)dt + \varepsilon \sqrt{v_t} dW_t^v.
\end{equation}
Procesy $dW_t^v$ oraz $dW_s^v$ są skorelowane na poziomie $\rho$:

\begin{equation}
Cov[dW^S_t, dW^v_t] = \rho dt.
\end{equation}
W powyższych wzorach $N_t^S$ jest procesem Poissona, $Y_t$ oznacza wysokość skoku, 
natomiast $S_{t-}$ oznacza, że skok dotyczy wartości procesu ceny przed skokiem.

Motywacją stojącą za wprowadzeniem skoków do modelu jest chęć uchwycenia momentów o 
szczególnej i gwałtownej zmianie ceny instrumentu bazowego. Dla indeksu S\&P, omawianego w tej pracy,
skoki są szczególnie widoczne podczas kryzysów ekonomicznych. 



 


%===========================================================================
%                       Kalibracja modelu Hestona
%===========================================================================
\chapter{Kalibracja modelu}
\label{chap:chapterModelCalibration}



Przed przystąpieniem do wyznaczenia ceny opcji w modelu Hestona potrzebujemy uzyskać zestaw 
parametrów ceny akcji i zmienności. Problem wyznaczenia parametrów modelu 
nazywamy \textbf{problemem kalibracji} modelu.  

Jak widzieliśmy w rozdziale \ref{chap:introduction}, zadanie kalibracji dla modelu Blacka-Scholesa 
nie jest zadaniem skomplikowanym. Do oszacowania mamy tylko jeden parametr, który należy wyznaczyć na 
podstawie danych giełdowych i odwróconego wzoru na cenę opcji w modelu Blacka-Scholesa.

Dla modelu Hestona sytuacja wygląda nieco bardziej skomplikowanie. Zamiast jednego mamy do 
oszacowania pięć parametrów:
$V(0),\kappa, \theta, \sigma, \rho$.  

Jednym ze sposobów kalibracji modelu jest technika symulowanego 
wyżarzania (ang. simulated annealing)\index{Symulowane wyżarzanie}. Należy ona do 
grona stochastycznych metaheurystyk, \index{Metaheurystyka} które pomagają w rozwiązaniu problemów 
optymalizacyjnych (a takim właśnie problemem 
jest kalibracja modelu, gdzie chcemy zminimalizować wartość funkcji będącej różnicą wartości funkcji 
wynikającej z modelu i z rynku). Kolejnym sposobem kalibracji jest powszechnie stosowana nielinowa
metoda najmniejszych kwadratów. 
Właśnie ta metoda zostanie użyta w niniejszej pracy w celu wyznaczenia parametrów modelu.

Warunkiem efektywnego zastosowania powyższej metody jest znalezienie szybkiego obliczeniowo sposobu 
wyznaczania wartości opcji w 
modelu Hestona. Ponieważ podejście symulacyjne jest zbyt czasochłonne w procesie kalibracji, stosuje 
się zamknięte równanie opisujące cenę opcji. Równanie to opisano w rozdziale \ref{chap:hestonModel}.


\section{Deterministyczne sposoby kalibracji modelu} 
Pierwsza grupa algorytmów używanych w celu skalibrowania modelu Hestona należy do grupy metod 
deterministycznych.
Algorytmy te polegają na tym, że mając zadany punkt startowy wyszukiwany jest najbardziej optymalny
punkt w sposób nielosowy.
Najważniejszym przedstawicielem tej klasy jest Nieliniowa Metoda Najmniejszych Kwadratów 
(\textit{ang. Nonlinear Least Squares}).


\subsection{Nieliniowa Metoda Najmniejszych Kwadratów \index{Nieliniowa Metoda Najmniejszych Kwadratów}}

Optymalizacja zadanej funkcji celu polega na dopasowaniu danych empirycznych do zadanej funkcji celu 
według pewnego zadanego kryterium (zadanej miary). 
Jedną z najczęściej używanych miar jest ta polegająca na minimalizacji kwadratów błędów estymacji. 
Najprostszą metodą z tej klasy jest (liniowa) Metoda Najmniejszych Kwadratów (MNK). \index{Metoda 
Najmniejszych Kwadratów} W świecie rzeczywistym jednak ciężko sobie wyobrazić, aby tego typu 
specyfikacja problemu modelowała wszystkie możliwe relacje ekonomiczne. 

Rozwiązaniem tego problemu jest osłabienie założenia dotyczącego liniowości zmiennych. W wyniku tego 
otrzymujemy nową metodę zwaną \textbf{Nieliniową Metodą Najmniejszych Kwadratów}.
Dla porządku, poniżej podajemy jej formalną specyfikację  \cite{NLS}.

\begin{defi}
 Rozważmy pewną nieliniową funkcję $f: R^l \times \Theta \rightarrow R$, gdzie $\Theta$ oznacza 
 przestrzeń parametrów i jest podprzestrzenią $R^k$. Wtedy $y$ można przedstawić jako:
\begin{equation}
  y = f(x; \beta) + e(\beta)
\end{equation}
gdzie funkcja $e(\beta)$ oznacza \textbf{błąd specyfikacji}. 
Mając $N$ obserwacji $y$ oraz wektor $x$, zdefiniujmy wektory \textbf{$y$} 
oraz $\mathbf{f(x_1, ... x_N; \beta)} $
w następujący sposób:

\begin{align}
\mathbf{y} &=  \begin{bmatrix}
         y_1 \\
         y_2 \\
         \vdots \\
         y_N
        \end{bmatrix},
&
\mathbf{f(x_1, x_2, \ldots, x_N; \beta}) &=  \begin{bmatrix}
         f(\mathbf{x_1; \beta})\\
         f(\mathbf{x_2; \beta})\\
         \vdots \\
         f(\mathbf{x_N; \beta})
        \end{bmatrix}
\end{align}
Wobec tego, 

\begin{equation}
 \mathbf{y = f(x; \beta) + e(\beta)}
\end{equation}
gdzie $\mathbf{e(\beta)}$ oznacza teraz wektor błędów specyfikacji.



\end{defi}


\subsection{Estymator NMNK}
Mając podaną specyfikację NMNK, chcielibyśmy znaleźć jego estymator, czyli taką statystykę, która 
najlepiej dopasowuje dane $(y_t, \mathbf{x_t}}), t = 1, ..., T$ względem zadanego kryterium. Tak jak 
w przypadku klasycznej MNK, także dla NMNK  
zminimalizujemy wartość sumy kwadratów różnic między wartościami empirycznymi, a teoretycznymi:
\begin{equation}
Q_T(\mathbf{\beta}) = \frac{1}{T} \sum_{t=1}^T [y_t - f(\mathbf{x_t, \beta})]^2
\end{equation}
Aby znaleźć ekstremum danej funkcji, należy znaleźć wektor parametrów spełniający 
następujące warunki:
\begin{itemize}
  \item Warunek pierwszego rzędu:
\begin{equation}
  \nabla Q_T(\mathbf{\bar{\beta}}) = 0
\end{equation}
  \item Warunek drugiego rzędu:
\begin{equation}
  \nabla^2 Q_T(\mathbf{\bar{\beta}}) > 0 
\end{equation}
\end{itemize}

Metoda minimalizująca wartość $Q_T(\mathbf{\beta})$ jest znana 
jako \textbf{estymator NMNK} (\textit{ang. NLS estimator}) i oznaczamy ja przez $\hat{\beta}_T$.

Należy zauważyć, że w przypadku metody MNK, jej estymator można podać w postaci wzoru
analitycznego. Nie zawsze jest to jednak możliwe dla metody NMNK, co wynika wprost z nieliniowości 
jej specyfikacji: pochodnych funkcji nieliniowych (potrzebnych do wyznaczenie warunku pierwszego rzędu) 
nie zawsze da się wyznaczyć analitycznie.


\begin{figure}
  \centering
  \includegraphics[width=0.80\textwidth]{../output/figures/NLS.pdf}
  \caption{Przykład dopasowania funkcji wykładniczej do danych}
  \label{fig:volatilitySurface}
\end{figure}




\subsection{Kalibracja modelu Hestona przy pomocy NMNK}

Warunek pierwszego rzędu dla funkcji nieliniowych z reguły
jest trudny do wyznaczenia analitycznego. Stosuje się więc metody numeryczne, które są metodami 
iteracyjnymi i zaczynającymi przeszukiwać przestrzeń w zadanym punkcie startowym (wybór punktu 
startowego może mieć duże znaczenie dla zbieżności metody).

Jedną z najprostszych jest \textbf{metoda największego spadku} 
(\textit{ang. steepest descent algorithm}). Jej idea polega na tym, że w 
każdym kroku algorytm stara się podążać w kierunku największego spadku, aż 
napotka ekstremum lokalne. Definicję pojedynczego kroku w tej metodzie 
przedstawia poniższe równanie:


\begin{equation}
  x_{k+1} = x_k - \alpha_k \nabla f(x_k)
\end{equation}
gdzie: $\nabla f(x_k)$ oznacza gradient, czyli pole wektorowe pokazujące kierunki najszybszego 
wzrostu, natomiast $e_k$ jest wektorem wartości rezydualnych.


Inna popularną metodą gradientową jest metoda Gaussa-Newtona. Różni się ona od metody największego 
spadku nieco innym schematem wyboru kierunku spadku. Nie używa ona gradientu, 
lecz informacji o krzywiźnie funkcji w danym punkcie (poprzez obliczenie pochodnych).
Podobnie jak dla metody najszybszego spadku definiujemy krok algorytmu jako:


\begin{equation}
  x_{k+1} = x_k - (J_k^TJ_k)^{-1}J_k e_k
\end{equation}
gdzie: $J_k$ oznacza macierz Jakobiego, czyli macierz pochodnych cząstkowych.

Obie te metody są wydajnymi sposobami obliczania ekstremów lokalnych, jednak mają swoje wady.
Zgodnie z literaturą \cite{LM}, pierwsza metoda dobrze się zachowuje dla punktów początkowych 
znajdujących się daleko od ekstremum, natomiast druga metoda zachowuje się dobrze w punktach 
położonych blisko ekstremum. 

Z połączenia dwóch przedstawionych powyżej metod powstał tzw. \textbf{algorytm Levenberga–Marquardta} 
(\textit{ang. Levenberg–Marquardt algorithm}). Został on zaimplementowany w pakiecie \textit{Matlab} 
jako funkcja \textit{lsqnonlin} \cite{NonLinear}\index{lsqnonlin}. Funkcja ta jest użyta w procesie 
kalibracji, którego wynik jest przedstawiony w rozdziale nr \ref{r:sp}, a jej nagłówek 
jest widoczny poniżej:

\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{matlab}
{listings/lsqnonlin.m}
\caption{Nagłówek funkcji \textit{lsqnonlin}}
\label{lst:lsqnonlin}
\end{listing}

Algorytm Levenberga–Marquardta można przedstawić jako niewielką modyfikację metody Gaussa-Newtona:


\begin{equation} 
  x_{k+1} = x_k - (J_k^TJ_k + \lambda I)^{-1}J_k e_k
\end{equation}
gdzie: $\lambda$ jest nazywany 
\textbf{współczynnikiem kombinacji} (\textit{ang. combination coefficient}) i 
ma zawsze wartość dodatnią.

Gdy współczynnik $\lambda$ jest bliski zero, to metoda ta zbiega do metody Gaussa-Newtona. 
Z kolei dla dużej wartości współczynnika $\lambda$ metoda zbliża się do metody największego spadku
z wartością współczynnika $\alpha_k$:

\begin{equation}
  \alpha_k = \frac{1}{\lambda}
\end{equation}
Tak jak pozostałe algorytmy z rodziny metod gradientowych, metoda Levenberga–Marquardta zachowuje się
bardzo dobrze dla funkcji z jednym ekstremum. Gdy jednak funkcja ma wiele ekstremów, bardzo ważną
rolę odgrywa punkt początkowy. Maksimum globalne możemy znaleźć tylko w przypadku jego bliskiego
położenia.



\subsection{Parametry wejściowe do procesu kalibracji}

Aby wyznaczyć parametry modelu jako dane wejściowe podajemy następujące dane dostępne na rynku:
\begin{enumerate}
  \item cenę wykonania opcji (ang. strike),
  \item czas wygaśnięcia opcji (ang. maturity).
\end{enumerate}
Są to dane wejściowe jakie należy podać w formie wektorów o jednakowej długości.
Ponadto, do metody kalibrującej parametry modelu Hestona należy podać następujące 
wartości skalarne:
\begin{enumerate}
  \item wartość aktywa bazowego w momencie $t=0$,
  \item stopę wolną od ryzyka.
\end{enumerate}

\section{Techniki przyspieszenia procesu kalibracji} %
Kalibracja modeli zmienności stochastycznej jest zadaniem czasochłonnym obliczeniowo. 
Istnieją jednak sposoby na jego przyspieszenie. W podrozdziale zostaną przedstawione 
dwie główne techniki stosowane w tym celu: uproszczenie równania opisującego cenę opcji 
w modelu oraz spamiętywanie powtarzających się wartości funkcji charakterystycznej.


\subsection{Zastosowanie uproszczonej formy ceny opcji w modelu Hestona} % (fold)
\label{sec:uproszczona_forma}

Pierwszą techniką przyspieszającą proces kalibracji jest zastosowanie uproszczonej formy ceny opcji w 
modelu Hestona. 
Opisana w podrozdziale \ref{sec:numeryczne_wyznaczenie_warto_ci_funkcji_charakterystycznej} 
formuła ma dwie przewagi nad tą przedstawioną przez Hestona:
\begin{enumerate}
  \item Formuła zawiera tylko jedną funkcję podcałkową do obliczenia
  \item Funkcja podcałkowa ma wyrażenie kwadratowe w mianowniku, co daje szybszą zbieżność  \cite{Attari}
\end{enumerate}

\subsection{Zapamiętywanie wartości funkcji charakterystycznej}
Postać funkcji charakterystycznej dla modelu Hestona jest bardzo czasochłonna obliczeniowo. 
Zawiera ona wiele skomplikowanych funkcji z punktu widzenia procesora:
\begin{itemize}
  \item dwie zespolone funkcji ekspotencjalne
  \item dwie zespolone funkcji logarytmiczne
  \item zespoloną funkcję pierwiastkową
\end{itemize}
Nie są one zależne w żaden sposób od parametrów wejściowych procedury kalibrującej (ceny wykupu oraz 
czasu do wygaśnięcia), dlatego też nie ma powodu ich wyliczania dla każdej pary. 
Stosuję się więc ich spamiętywanie (\textit{ang. caching}).
Tak wyglądałby schemat działania metody kalibrującej \cite{AcceleratingHeston} przed zastosowaniem 
techniki spamiętywania:
\begin{algorithm}[H]
\caption{Schemat metody kalibrującej}\label{euclid}
\begin{algorithmic}[1]
  \State Iteruj po wszystkich wartościach czasu do wygaśnięcia opcji
  \State Iteruj po wszystkich wartościach ceny wykonania opcji
  \State Iteruj po wszystkich wartościach $\omega_i, i = 1, ..., U $ użytych do numerycznego wyznaczenia całki z równania   
  \State Oblicz wartość funkcji charakterystycznej w punkcie $\omega_i$
  \State Oblicz wartość całki w punkcie $\omega_i$
  \State Oblicz wartość opcji
\end{algorithmic}
\label{alg:simulatedAnnealing}
\end{algorithm}
Zauważmy, że wartość funkcji charakterystycznej w punkcie $\omega_i$ jest niezależna od czasu do 
wygaśnięcia opcji oraz ceny jej wykonania. Można zatem zoptymalizować krok w linii nr 4. Tak wygląda 
algorytm po zastosowaniu spamiętywania wartości funkcji charakterystycznej:

\begin{algorithm}[H]
\caption{Schemat metody kalibrującej ze zapamiętywaniem}\label{euclid}

\begin{algorithmic}[1]
  
  \State Iteruj po wszystkich wartościach czasu do wygaśnięcia opcji
  \State Iteruj po wszystkich wartościach ceny wykonania opcji
  \State Iteruj po wszystkich wartościach $\omega_i, i = 1, ..., U $ użytych do numerycznego wyznaczenia całki z równania   
  \State Jeżeli jesteśmy w pierwszym kroku pętli, oblicz i zapamiętaj $\omega_i$
  \State Jeżeli nie jesteśmy w pierwszym kroku pętli, odczytaj zapisaną wartość $\omega_i$
  \State Oblicz wartość całki w punkcie $\omega_i$
  \State Oblicz wartość opcji

\end{algorithmic}
\label{alg:simulatedAnnealing}
\end{algorithm}




Na podstawie powyżej przedstawionych pseudokodów widać, że obliczamy funkcję 
charakterystyczną tylko raz, podczas pierwszego obrotu wewnętrznej pętli.



\section{Stochastyczne sposoby kalibracji modelu}
Przedstawione jak do tej pory algorytmy optymalizacyjne są algorytmami deterministycznymi.
Często jednak wprowadzenie czynnika losowego może poprawić ich efektywność lub dokładność. Jednym z
nich jest algorytm symulowanego wyżarzania, który nadaje się szczególnie dobrze do efektywnego
przeglądu tych klas funkcji, które mają nieregularną powierzchnię, tzn. takich, w których występuje
wiele ekstremów lokalnych.

\subsection{Symulowane wyżarzanie}

Jak opisano we wstępie, większość algorytmów, nigdy nie osiągną ekstremum
globalnego. Jedną z takich technik jest \textit{hill climbing}\index{Hill climbing}, która jednak 
osiąga dobre rezultaty tylko dla funkcji o wypukłej powierzchni. W tym algorytmie możemy poruszać się
tylko w kierunku maksimum lokalnego, co skutecznie uniemożliwia przeszukiwanie przestrzeni o wielu
ekstremach.

Wprowadza się zatem odstępstwo od tej reguły. Pod pewnym warunkiem można przeskoczyć od 
jednego wzgórza do drugiego, co pomaga algorytmowi poruszać się w obrębie wielu ekstremów lokalnych.
Można to osiągnąć poprzez wprowadzenie losowości do algorytmu. 

Otrzymujemy w ten sposób stochastyczne metody optymalizacji, a jednym z najważniejszych 
reprezentantów tej klasy metod jest przedstawiony w 1983 roku przez Kirkpatricka 
\cite{Kirkpatrick},  algorytm symulowanego wyżarzania  (\textit{ang. simulated annealing}). 
Motywacją dla jego powstania jest szeroko stosowany w metalurgii \textbf{proces chłodzenia}
\index{Proces chłodzenia} ciała stałego (\textit{ang. cooling process}). Składa on się z
następujących etapów  \cite{ChenBin}:

\begin{enumerate}
  \item Podnoszenia temperatury, tak, że substancja stała się topi,
  \item Powolnego wychładzania substancji tak, że poruszające się tam cząsteczki gromadzą się w stanie o najmniejszej energii.
\end{enumerate}

Dobrym przykładem obrazującym działanie algorytmu jest wyobrażenie skaczącej piłki na terenie 
o nierównej powierzchni.
W warunkach niskiej siły grawitacji, piłka odbijając się od powierzchni leci wysoko w górę i może
przeskoczyć z jednej doliny do drugiej, natomiast odwrotnie się dzieje w przypadku wysokiej siły
grawitacji. Wtedy piłce trudniej jest się oderwać od powierzchni i wydostać się z doliny. Podobnie
sprawa ma się w przypadku cząsteczek umieszczonych w metalu: przy wysokiej 
temperaturze mogą się one swobodnie przemieszczać w ciele, natomiast wraz ze spadającą temperaturą 
stają się one uwięzione w jednym punkcie.

Przedstawiona idea rozwiązuje szereg problemów podczas rozwiązywania problemów optymalizacyjnych, a 
najważniejszym z nich jest potencjalne istnienie wielu ekstremów lokalnych.

\begin{algorithm}[H]
\caption{Algorytm symulowanego wyżarzania}\label{euclid}

\begin{algorithmic}[1]
  
  \State Zainicjuj temperaturę początkową $T_0$;
  \State Zainicjuj rozwiązanie początkowe $x_0$;
  \State Dla każdego poziomu temperatury $T_K$:
  \State  \hspace{\algorithmicindent} Zdefiniuj funkcję $\pi_k(x) = e^{- \frac{G(x)}{T_k}}$
  \State  \hspace{\algorithmicindent}    Wykonaj $n$ iteracji:
  \State    \hspace{\algorithmicindent} \hspace{\algorithmicindent}       Zaakceptuj nowe rozwiązanie $x_{k+1}$ z pr-stwem $min(1, \frac{\pi_k{x_{k+1}}}\pi_k{{x_{k}}}$);
  \State Jeżeli $T_{k+1} < T_{min}$:
  \State  \hspace{\algorithmicindent}    Zakończ algorytm;
  \State W przeciwnym przypadku:
  \State   \hspace{\algorithmicindent}   Skocz do linii 3 z temperaturą $T_{k+1}$ oraz rozwiązaniem $x_{k+1}$;

\end{algorithmic}
\label{alg:simulatedAnnealing}
\end{algorithm}

Działanie algorytmu symulowanego wyżarzania można zobaczyć na schemacie nr 
\ref{alg:simulatedAnnealing}. Poniżej pokrótce omówimy działanie algorytmu.
Funkcja ma dwa argumenty: pierwszy argument dotyczy wysokości temperatury początkowej (i ewentualnie
szybkości chłodzenia systemu), natomiast drugi rozwiązanie początkowe.
Najważniejszą częścią algorytmu jest pętla 4-6. 
Centralną rolę odgrywa tam reguła Metropolisa, która mówi czy bieżące rozwiązanie powinno być 
zaakceptowane czy nie (najważniejszym parametrem jest bieżąca temperatura systemu). 
Linie 7-10 to już tylko sprawdzenie warunku końcowego: jeżeli temperatura jest dostatecznie 
niska to kończymy algorytm, ponieważ wiemy, że i tak nie znajdziemy bardziej optymalnego rozwiązania.



%===========================================================================
%                       Metody Monte Carlo
%===========================================================================
\chapter{Metody Monte Carlo}
\label{chap:monteCarlo}

Przeprowadzenie wyceny opcji w modelu Hestona jest zadaniem znacznie trudniejszym
niż w przypadku modelu BS. Wynika to z tego, że w modelu Hestona trajektoria 
ceny instrumentu bazowego jest zależna od trajektorii jego zmienności. To pociąga za sobą
konsekwencje w procesie wyceny opcji, ponieważ teraz należy najpierw wygenerować trajektorię
zmienności, a dopiero później, na tej podstawie, generować trajektorię cen instrumentu bazowego.

Aby jednak wygenerować trajektorię cen, musimy być w stanie przedstawić równanie opisujące
zmienność aktywa bazowego w postaci \textit{zdyskretyzowanej}.

W tym rozdziale pokażemy jak efektywnie, przy pomocy schematów dyskretyzacji i symulacji Monte Carlo, 
wyznaczyć najpierw trajektorie procesu zmienności i aktywa bazowego, a następnie wyliczyć wartość
opcji o zadanym schemacie wypłaty.

\section{Prosta metoda Monte Carlo (MC)}
\label{sec:mc}

Rozdział zaczynamy od przedstawienia prostej metody 
Monte Carlo (\textit{ang. Crude Monte Carlo (CMC)}) \cite{Niemiro}.

\begin{defi}
Załóżmy, że mamy wygenerowane $n$ zmiennych losowych $X_1, ..., X_n$ o takim samym rozkładzie. 
Wtedy estymatorem wartości oczekiwanej $EX$ jest średnia z próby:
\begin{equation}
  \hat{\theta}_n = \sum_{i=1}^n \frac{X_i}{n}
\end{equation}
Inaczej mówiąc, aproksymujemy prawdziwą wartość oczekiwaną 
\textbf{średnią z próby} (\textit{ang. sample mean}).
\end{defi}


Zgodnie z Mocnym Prawem Wielkich Liczb mamy pewność, że estymator 
$\hat{\theta}_n \rightarrow EX$ prawie na pewno, wtedy gdy $n \rightarrow \infty$. 
Oznacza to, że estymator $\hat{\theta}_n $ jest \textbf{mocno zgodnym} 
estymatorem $EX$ \cite{Glasserman}.



\section{Generowanie zmiennych losowych}
\label{sec:genRV}

Efektywność przedstawionej metody Monte Carlo wynika z łatwości uzyskania dowolnie dużej
ilości liczb losowych. 
W tym podrozdziale zostaną pokazane najważniejsze sposoby generowania liczb losowych.


\subsection{Generowanie zmiennych losowych o rozkładzie normalnym}

Pierwszym krokiem jaki należy podjąć podczas przeprowadzania symulacji Monte Carlo jest 
wygenerowanie zmiennych losowych o ustalonym rozkładzie.

W przypadku wyceny opcji w modelu Blacka-Scholesa potrzebna jest umiejętność generowania liczb 
(pseudo)losowych z rozkładu normalnego. Znamy wiele algorytmów generowania liczb o rozkładzie
normalnym, wśród których można wyróżnić:
\begin{enumerate}
  \item metoda odwrotnej dystrybuanty,
  \item metoda Boxa-Mullera,
  \item metoda biegunów (\textit{ang. Marsaglia\index{Marsaglia, George} Polar Method}) \cite{Marsaglia},
  \item algorytm ziggurat.
\end{enumerate}

Mimo, że najbardziej wydajną metodą generowania liczb pseudolosowych o rozkładzie normalnym jest 
algorytm ziggurat, a najbardziej ogólną jest metoda odwrotnej dystrybuanty (pozwala na generowanie 
liczb o dowolnym rozkładzie pod warunkiem umiejętności wyznaczenia funkcji odwrotnej do dystrybuanty 
danego rozkładu), w tym rozdziale zostanie przedstawiona metoda biegunów.

Jest ona wariantem metody Boxa-Mullera\index{Box, George}\index{Muller, Edgar}. W przeciwieństwie do 
metody Boxa-Mullera nie zawiera ona funkcji $sin$ oraz $cos$, dlatego też jest znacznie wydajniejsza 
obliczeniowo \cite{Korn}.
Polega ona na wybraniu losowego punktu $(x,y)$ z rozkładu jednostajnego spełniającego warunek:
\begin{equation}
  \{(x, y): s = x^2 + y^2 < 1\}
\end{equation}
Wtedy liczby losowe o standardowym rozkładzie normalnym otrzymujemy stosując następujące 
przekształcenia:
\begin{equation}
  u_1 = x \sqrt{\frac{-2 \ln(s)}{s}}, u_2 = y \sqrt{\frac{-2 \ln(s)}{s}}
\end{equation}
Pseudokod \ref{lst:polarMethodLst} przedstawia zarys algorytmu generowania zmiennej losowej o standardowym rozkładzie
normalnym przy pomocy wyżej opisanego schematu. 

\begin{algorithm}[H]
\caption{Generowanie zmiennej losowej o standardowym rozkładzie normalnym zgodnie z metodą biegunów}
\label{lst:polarMethodLst}

\begin{algorithmic}[1]

  \State do \{
  \State \hspace{\algorithmicindent} $x = 2.0$ $\cdot$ Uniform(0,1)
  \State \hspace{\algorithmicindent} $y = 2.0$ $\cdot$ Uniform(0,1)
  \State \hspace{\algorithmicindent} $s = x^2 + y^2$
  \State \}
  \State while ($s \geq 1.0$)
  \State return $x \cdot \sqrt{\frac{-2 \ln(s)}{s}}$

\end{algorithmic}
\label{alg:polarMethod}
\end{algorithm}





\subsection{Generowanie skorelowanych ruchów Browna}
\label{sec:genRB}

Ważną kwestią, która pojawia się podczas implementacji modelu Hestona, jest generowanie skorelowanych 
ruchów Browna.

Dla przypadku dwuwymiarowego problem redukuje się do 
następującej postaci:

\begin{equation}
  \varepsilon_1 = x_1
\end{equation}
\begin{equation}
  \varepsilon_2 = \rho x_1 + x_2 \sqrt{1-\rho^2}
\end{equation}
gdzie:
\begin{enumerate}
  \item $x_i$ - wygenerowana zmienna losowa z rozkładu normalnego
  \item $\rho$  - współczynnik korelacji
\end{enumerate}




\section{Schematy dyskretyzacji}


Model Hestona, opisany w Rozdziale \ref{chap:hestonModel}, opisuje dynamikę procesów cen aktywa 
bazowego oraz jego zmienności w postaci ciągłej.
Chcąc jednak wycenić opcję \textit{call} przy pomocy metody Monte Carlo, należy wygenerować 
trajektorie procesów w nim występujących w postaci dyskretnej. 

Następujący podrozdział będzie poświęcony metodom dyskretyzacji występującym w literaturze.

\subsection{Generowanie trajektorii procesu stochastycznego}
Generowanie trajektorii procesów stochastycznych występujących w modelu Hestona polega na
wygenerowaniu pary wektorów losowych o elementach $(S(t), v(t))$, dla każdego $t \in \mathscr{T}$, 
gdzie $\mathscr{T}$ jest danym zbiorem dyskretnych punktów w czasie 
$\mathscr{T}  = \{t_i\}^N_{t=1}$. Aby wygenerować taką parę wektorów losowych wystarczy znać 
odpowiedź na inne fundamentalne pytanie: jak można wygenerować punkty wektorów losowych 
$(S(t+ \Delta), v(t+ \Delta))$
mając dany punkt $(S(t), v(t))$? Mając taki schemat, można go iteracyjnie lub rekurencyjnie aplikować 
dla każdego kolejnego punktu począwszy od zadanego elementu $(S(0), v(0))$, 
aż do otrzymania punktu $(S(T), v(T))$.
Kolejne podrozdziały będą odpowiedzią na pytanie właśnie jakie schematy można zastosować w celu 
efektywnego przejścia od $(S(t), v(t))$ do $(S(t+ \Delta), v(t+ \Delta))$.

Używamy w nich notacji $\hat{S}, \hat{v}$ dla oznaczenia dyskretnych trajektorii procesów 
stochastycznych $S, v$.

\subsection{Dyskretyzacja Eulera}

Poniższe równanie nr \ref{h:euler} przedstawia \textbf{dyskretyzację Eulera} równania 
zmienności \cite{Broadie}:
 
\begin{equation}\label{h:euler}
v_{i+1}  = v_i + \kappa (\theta - v_i) \Delta t + \varepsilon  \sqrt{v_i} \Delta W^{v}_{i+1}.
\end{equation}
gdzie: $\Delta W^{v}_{i+1} = W^{v} (t_i+\Delta) - W^{v} (t_i)$.

Powyższe równanie jest wynikiem dyskretyzacji procesu ciągłego do procesu dyskretnego. Przejście
takie jest jednak podatne na numeryczne błędy zaokrągleń. Niestety, pomimo faktu, że 
proces zmienności $v_t$ w postaci ciągłej nie może osiągnąć wartości ujemnej, po 
dyskretyzacji okazuje się, że wartość ta może być ujemna. 

Aby tego uniknąć, wszędzie tam, gdzie możliwe jest wystąpienie ujemnej 
wartości zmienności $v_i$, zastępujemy ją poprzez $v_i^+ = \max(v_i, 0)$. Operacja taka nazywana jest 
\textbf{pełnym obcięciem} (\textit{ang. full truncation})\index{Full truncation} \cite{Lord}.
Rozwiązanie to, jak do tej pory, okazało się być najbardziej dokładnym i 
efektywnym w swojej klasie \cite{Malham}. Ostatecznie więc, wzór opisujący dynamikę $v_i$ przyjmuje 
postać:

\begin{equation}\label{h:eulerNonZero}
v_{i+1}  = v_i + \kappa (\theta - v_i^+) \Delta t + \varepsilon \sqrt{v_i^+} \Delta W^{v}_{i+1}.
\end{equation}

Mając wygenerowaną trajektorię zmienności, można przystąpić do zdyskretyzowania równania opisującego 
dynamikę cen aktywa bazowego, jednakże pamiętając o tym, aby zmienność zawsze była wartością 
dodatnią. 
Mając to na uwadze, równanie (\ref{h:eulerAssetPath}) opisuję dynamikę cen instrumentu bazowego w 
postaci dyskretnej:

\begin{equation}\label{h:eulerAssetPath}
S_{i+1} = S_i + S_i r \Delta t + S_i \sqrt{v_i^+}  \Delta W_{i+1}^S.
\end{equation}
gdzie: $\Delta W^{S}_{i+1} = W^{S} (t_i+\Delta) - W^{S} (t_i)$.
  
Aby wygenerować przyrosty procesu Wienera wykorzystujemy fakt, że $W_{i+1}  - W_{i}$ są niezależne 
względem pozostałych przyrostów. 
Każdy taki przyrost ma rozkład normalny o średniej równej $0$ oraz odchyleniu standardowym 
równym $\sqrt{\Delta t}$. 
Dlatego do wygenerowania przyrostów procesu Wienera można zastosować metody przedstawione w 
podrozdziale \ref{sec:genRV} \cite{Glasserman}.


\subsection{Schemat Andersena - dyskretyzacja procesu zmienności}
\label{sec:algorytm_andersena}
O ile schemat dyskretyzacji Eulera jest najprostszym do implementacji schematem dyskretyzacji, to ma 
on wiele wad jak np.  
Algorytm Andersena \cite{Andersen}, zwany również pod nazwą schematu 
kwadratowo-wykładniczego (\textit{ang. Quadratic Expotential (QE) scheme}),
znacząco niweluje te wady, czyniąc proces dyskretyzacji bardziej dokładnym przy niewiele wolniejszym 
tempie wykonania algorytmu. 

Zanim przejdziemy do opisu schematu, przedstawiona zostanie warunkowa wartość oczekiwana i wariancja 
procesu wariancji w modelu Hestona. Wartości te będą stanowiły istotny punkt algorytmu Andersena.
\begin{prop}
Pod warunkiem $\hat{v}(t)$, średnia $m$ oraz wariancja $s^2$ zmiennej $\hat{v}(t + \Delta)$ przyjmuje 
postać:

\begin{equation}
  \label{eq:m}
  m= \theta + (\hat{v}(t) - \theta) e^{-\kappa \Delta}
\end{equation}

\begin{equation}
  \label{eq:s2}
  s^2 = \frac{\hat{v}(t)\varepsilon^2 e^{-\kappa \Delta}}{\kappa} (1 - e^{-\kappa \Delta}) 
  + \frac{\theta \varepsilon^2}{2 \kappa}(1 - e^{-\kappa \Delta})^2
\end{equation}
\end{prop}
 

Aplikując schemat Andersena, będziemy chcieli aproksymować wartość  $\hat{v}(t + \Delta)$ w 
zależności od wartości zmiennej $\hat{v}(t)$. Wartość $\hat{v}(t)$ wpływa na parametr 
$\Psi$ zdefiniowany jako:


\begin{equation}
 \label{eq:ksi}
 \Psi = \frac{s^2}{m^2} = \frac{\frac{\hat{v}(t)\varepsilon^2 e^{-\kappa \Delta}}{\kappa} 
 (1 - e^{-\kappa \Delta}) + \frac{\theta \varepsilon^2}{2 \kappa}(1 - e^{-\kappa \Delta})^2}
 {(\theta + (\hat{v}(t) - \theta) e^{-\kappa \Delta})^2} 
\end{equation}
gdzie $m$ i $s^2$ zdefiniowane są przy pomocy równań \ref{eq:m} oraz \ref{eq:s2}.
Dla wartości parametru $\Psi \leq 2.0$, definiuje się wartość zmiennej $\hat{v}(t + \Delta)$ pod 
warunkiem $\hat{v}(t)$ jako:
\begin{equation}
 \label{eq:vtbig}
\hat{v}(t + \Delta)  = a (b + Z_V)^2
\end{equation}
gdzie $Z_V$ jest zmienną o standardowym rozkładzie normalnym. Zmienne $a$ i $b$ zdefiniowane są 
natomiast przy pomocy dopasowania pierwszego i drugiego momentu (\textit{ang. moments matching}) 
procesu wariancji i mają wartość:


\begin{equation}
\label{eq:b}
b^2 = 2 \Psi^{-1} - 1 + \sqrt{2 \Psi^{-1}} \sqrt{2 \Psi^{-1} - 1}
\end{equation}

\begin{equation}
\label{eq:a}
a = \frac{m}{1 + b^2}
\end{equation}
Aproksymacja zdefiniowana w powyższy sposób znana jest pod nazwą 
\textbf{aproksymacji kwadratowej Gaussa} (\textit{ang. quadratic Gaussian approximation}).


Schemat \ref{eq:vtbig} nie działa jednak zbyt dobrze dla małych wartości $\hat{v}(t)$. Zawodzi metoda 
dopasowania momentów, dlatego w tym przypadku 
zostanie zastosowany inny schemat. Polega on na tym, że dla $\Psi \geq 1$, wartość 
$\hat{v}(t + \Delta)$ pod warunkiem znanej wartości $\hat{v}(t)$ można otrzymać 
stosując następujące przekształcenie:

\begin{equation}
\label{eq:psi}
F^{-1}(u) = F^{-1}(u;p,\beta) = \begin{cases}
               0, & 0 \le u \leq p,\\
               \beta^{-1} \ln (\frac{1-p}{1-u}), & p < u < 1, \\
            \end{cases} 
\end{equation} 
gdzie $u \in U_V$ jest realizacją zmiennej losowej z rozkładu jednostajnego, $F^{-1}$ oznacza
odwrotną dystrybuantę gęstości prawdopodobieństwa, natomiast $p$ oraz $\beta$ mają postać:

\begin{equation}
\label{eq:beta}
\beta = \frac{1-p}{m} = \frac{2}{m(\Psi + 1)}
\end{equation}

\begin{equation}
\label{eq:p}
p = \frac{\Psi - 1}{\Psi + 1}
\end{equation}

Schemat ten znany jest w literaturze pod nazwą \textbf{aproksymacji przy pomocy 
zero-zmodyfikowanego rozkładu wykładniczego} (ang. zero-modified exponential approximation). 
Jest to aproksymacja, która w części niezerowej ma 
rozkład wykładniczy, natomiast dla zera przyjmuje inną wartość, spoza rozkładu. 


Obydwa schematy można złączyć w jedno równanie o postaci:
\begin{equation}
\label{eq:andersen}
\hat{v}(t + \Delta)  = \mathds{1}_{\Phi \geq \Phi_c} a (b + Z_V)^2
 + \mathds{1}_{\Phi \le \Phi_c} \beta^{-1} \ln (\frac{1-p}{1-u})
\end{equation}
gdzie $Z$ jest standardowym rozkładem normalnym, natomiast $U$ jest rozkładem jednostajnym na 
przedziale $[0;1]$.


Jedynym nieprecyzyjnym punktem jest wybór wartości krytycznej $\Psi_c$, czyli granicznej wartości dla 
której przychodzimy z jednego schematu aproksymacji w drugi. 
Z poprzednich równań wynika, że obszar niekonkluzywności jest zawarty w przedziale $\Psi \in [1;2]$.
Jak jednak podaje w swojej pracy autor algorytmu, wybór konkretnej metody w tym przedziale ma 
niewielki wpływ na jakość całego schematu aproksymacji, dlatego można wartość tę ustalić na 
arbitralnym poziomie $\Psi_c = 1.5$. 
 


W pracy \textbf{Leifa Andersena}\index{Andersen, Leif} \cite{Andersen} został 
przedstawiony algorytm wyznaczenia 
wartości $\hat{v}(t + \Delta)$ na podstawie $\hat{v}(t)$. Przy założeniu, 
że w sposób arbitralny wyznaczono parametr $\Psi_c \in [1,2]$, algorytm 
ma następującą postać:

\begin{algorithm}[H]
\caption{Dyskretyzacja procesu zmienności przy pomocy algorytmu Andersena}\label{andersenAlgorithmLabel}

\begin{algorithmic}[1]
 
  \State Oblicz $m$ oraz $s^2$ na podstawie równań $\hat{v}(t)$ oraz równań (\ref{eq:m}) i (\ref{eq:s2}) odpowiednio
  \State Wyznacz $\Psi = \frac{s^2}{m^2}$ 
  % i wyznacz $f_{\mu}(\Psi)$ oraz $f_{\sigma}(\Psi)$ 
  \State Wylosuj liczbę $U_V$ z rozkładu jednostajnego 
  \State Jeżeli $\Psi \leq \Psi_c$:
  \State \hspace{\algorithmicindent} wyznacz $a$ i $b$ na podstawie (\ref{eq:b}) oraz (\ref{eq:a})
  \State \hspace{\algorithmicindent} oblicz $Z_V = \Phi^{-1}(U_V)$
  \State \hspace{\algorithmicindent} oblicz $\hat{v}(t + \Delta)  = a(b+ Z_V)^2$
  \State W przeciwnym przypadku:
  \State \hspace{\algorithmicindent} wyznacz $\beta$ oraz $p$ zgodnie z równaniami (\ref{eq:beta}) i (\ref{eq:p})
  \State \hspace{\algorithmicindent} oblicz $\hat{v}(t + \Delta)  =\Psi^{-1}(U_V;p,\beta$), 
                                     gdzie $\Psi^{-1}$ jest dane w równaniu (\ref{eq:psi})
\end{algorithmic}
\label{alg:andersenAlgorithm}
\end{algorithm}



W celu poprawy wydajności algorytmu, wartości parametrów $m$ i $s^2$ powinny zostać obliczone poza 
główną pętlą schematu Monte Carlo.



\subsection{Schemat Andersena - dyskretyzacja procesu aktywa bazowego}

Na podstawie wyznaczonej trajektorii procesu wariancji należy wygenerować trajektoria aktywa bazowego 
$S(t)$. Wydawać się może, na pierwszy rzut oka, że dobrym sposobem jest wygenerowanie tej trajektorii 
przy pomocy schematu Eulera. Niestety, w schemacie Eulera możemy wygenerować skorelowane zmienne 
losowe przy pomocy metody podanej w punkcie \ref{sec:genRB}.
W schemacie Andersena, do wygenerowania elementów procesu losowego $v(t)$ używamy albo zmiennej 
losowej o rozkładzie normalnym albo zmiennej losowej z rozkładu jednostajnego. Dlatego, też nie jest 
jasne jak dobrze skorelować proces $S(t)$ z $v(t)$. Próba skorelowania $W^S$ ze zmienną $W^V$
spowodowałaby, że korelacja pomiędzy procesami byłaby zbyt mała. Zjawisko takie jest znane w 
literaturze pod nazwą \textbf{wycieku korelacji} 
(ang. \textit{leaking correlation}) \cite{Andersen}\index{Leaking correlation}. 

Andersen proponuje więc użyć dokładnej reprezentacji wartości procesu $\ln S(t + \Delta)$:

\begin{equation}
\begin{aligned}
\label{eq:xt}
\ln S(t + \Delta) = & \ln S(t) + r \Delta + \frac{\rho}{\varepsilon} (v(t + \Delta)  - v(t) - \kappa \theta \Delta) + \\
& \Big( \frac{\kappa \rho}{\varepsilon} - \frac{1}{2} \Big)
\int_t^{t+\Delta} v(u) du + \sqrt{1-\rho^2} \int_t^{t+\Delta} \sqrt{v(u)}dW(u)
\end{aligned}
\end{equation}
gdzie:

Składnik $\frac{\rho}{\varepsilon} (V(t + \Delta)$ jest elementem, który odpowiada za korelację między 
procesami $V(t + \Delta)$ oraz $X(t + \Delta)$.

Istotną kwestią pozostaje znalezienie sposobu na oszacowanie całki występującej we wzorze (\ref{eq:xt}):
\begin{equation}
  \int_t^{t+\Delta}  V(u) du \approx \Delta [\gamma_1 V(t) + \gamma_2 V(t + \Delta)]
\end{equation}

Równanie to aproksymuje całkę na przedziale $[t; t + \Delta]$ 
jako przyrost argumentów pomnożony przez średnią ważoną wartości w punktach brzegowych, gdzie wagami 
są pewne stałe $\gamma_1$ oraz $\gamma_2$. Na podstawie tego można wyznaczyć 
następujący schemat aproksymacji dla zlogarytmowanego procesu aktywa bazowego:
\begin{equation}
\begin{aligned}
\label{eq:lnxhatt}
\ln \hat{S}(t + \Delta) = & \ln \hat{S}(t)  + \frac{\rho}{\varepsilon} (V(t + \Delta)  - V(t) - \kappa \theta \Delta) + \\
& + \Delta \Big( \frac{\kappa \rho}{\varepsilon} - \frac{1}{2} \Big) (\gamma_1 \hat{v}(t) + \gamma_2 \hat{v}(t + \Delta)) + \\
& + \sqrt{1-\rho^2} \sqrt{\gamma_1 \hat{v}(t) + \gamma_2 \hat{v}(t + \Delta)} \cdot Z,
\end{aligned}
\end{equation}
gdzie: 
\begin{itemize}
  \item $Z \sim N(0,1)$,
  \item $Z$ jest niezależne.
\end{itemize}

Na koniec pozostaje przekształcić równanie (\ref{eq:lnxhatt}) tak, aby zamiast 
zmiennej $\ln X(t + \Delta)$ uzyskać zmienną $\ln X(t)$. Aplikując obustronnie
funkcję eksponencjalna otrzymujemy:
\begin{equation}
\begin{aligned}
\label{eq:xhatt}
\hat{S}(t + \Delta) = & \hat{S}(t)  + exp(\frac{\rho}{\varepsilon} 
(V(t + \Delta)  - V(t) - \kappa \theta \Delta) + \\
& + \Delta \Big( \frac{\kappa \rho}{\varepsilon} - 
\frac{1}{2} \Big) (\gamma_1 \hat{v}(t) + \gamma_2 \hat{v}(t + \Delta)) + \\
& + \sqrt{1-\rho^2} \sqrt{\gamma_1 \hat{v}(t) + \gamma_2 \hat{v}(t + \Delta)} \cdot Z),
\end{aligned}
\end{equation}
Równanie to można przedstawić w bardziej usystematyzowany sposób w następującej postaci:
\begin{equation}
\begin{aligned}
\label{eq:HestonInterest} 
\hat{S}(t + \Delta) &= \hat{S}(t) * exp(r \Delta +\\ 
                    &+ K_0 + K_1 \hat{v}(t) 
                    + K_2 \hat{v}(t+\Delta)
                    + \sqrt{K_3 \hat{v}(t) +  K_4 \hat{v}(t+\Delta)} \cdot Z)

\end{aligned}
\end{equation}
gdzie:
\begin{enumerate}
  \item $K_0 = - \frac{\rho \kappa \theta}{\varepsilon} \Delta$
  \item $K_1 = \gamma_1 \Delta \left(  \frac{\kappa \rho}{\varepsilon}  - \frac{1}{2}  \right) - \frac{\rho}{\varepsilon}$
  \item $K_2 = \gamma_2 \Delta \left(  \frac{\kappa \rho}{\varepsilon}  - \frac{1}{2}  \right) + \frac{\rho}{\varepsilon}$
  \item $K_3 = \gamma_1 \Delta (1 - \rho^2)$
  \item $K_4 = \gamma_2 \Delta (1 - \rho^2)$
\end{enumerate}


Wartość parametrów $\gamma_1$ oraz $\gamma_2$ można ustalić na wiele 
sposobów tak, aby $\gamma_1 + \gamma_2 = 1$. 
Jednym z nich jest podstawienie pod $\gamma_1 = 1$ oraz $\gamma_2 = 0$. Otrzymany w ten sposób 
schemat dyskretyzacji nazywamy, przedstawioną wcześniej, \textbf{dyskretyzacją Eulera}.

Można więc przedstawić następujący algorytm wyznaczenia punktów 
$(\hat{S}(t+ \Delta), \hat{v}(t+ \Delta))$ na podstawie $(\hat{S}(t), \hat{v}(t))$:
 
\begin{algorithm}[H]
\caption{Dyskretyzacja procesu aktywa bazowego w oparciu o schemat Andersena}\label{andersenAlgorithmAssetLabel}

\begin{algorithmic}[1]

  \State Mając $\hat{v}(t)$ wyznacz $\hat{v}(t + \Delta)$ na podstawie 
         schematu z poprzedniego podrozdziału \ref{sec:algorytm_andersena}.
  \State Wylosuj liczbę z rozkładu jednostajnego $U$, niezależnej 
         od wszystkich liczb losowych z równania dla $\hat{v}(t + \Delta)$.
  \State Wyznacz $Z = \Phi^{-1}(U)$.
  \State Mając $\ln \hat{S}(t), \hat{v}(t)$ oraz wartość dla $\hat{v}(t + \Delta)$ 
         wyznacz $\ln \hat{S} (t+\Delta)$ używając równania (\ref{eq:xhatt}).

\end{algorithmic}
\label{alg:andersenAlgorithmAsset}
\end{algorithm}


 
\subsection{Dyskretyzacja aktywa bazowego z poprawką martyngałową}

Przedstawiony na równaniu (\ref{eq:heston1}) proces aktywa bazowego charakteryzuje się dryftem dla
niezerowej wartości stopy procentowej $r$.
Przy założeniu jednak, że stopa procentowa wynosi $r = 0$, proces aktywa 
bazowego opisany równaniem (\ref{eq:heston1}) miałby
następującą formę:
\begin{equation}
\label{eq:AssetNoInterest}
dS(t)  = \sqrt{v(t)} S(t) dW^S(t)
\end{equation}
Dyskretyzacja tego procesu, zgodnie z modelem Hestona wyglądałaby następująco:
\begin{equation}
\begin{aligned}
\label{eq:HestonNoInterest} 
\hat{S}(t + \Delta) &= \hat{S}(t) * exp(\\ 
                    &+ K_0 + K_1 \hat{v}(t) 
                    + K_2 \hat{v}(t+\Delta)
                    + \sqrt{K_3 \hat{v}(t) +  K_4 \hat{v}(t+\Delta)} \cdot Z)

\end{aligned}
\end{equation}
Gdzie parametry $K_i$, dla $i \in [0..4]$ są takie same jak dla równania (\ref{eq:HestonInterest}).
Równanie (\ref{eq:AssetNoInterest}) można sprowadzić do następującej postaci:
\begin{equation}
dS(t)/S(t) = \sqrt{v(t)}  dW^S(t)
\end{equation}
Powyższe równanie przedstawia proces, który jest martyngałem, tzn. 
\begin{equation}
E(S(t + \Delta)| S(t)) = S(t) < \infty
\end{equation}
Wartość oczekiwana aktywa bazowego, zgodna z równaniem (\ref{eq:HestonNoInterest})
nie jest jednak martyngałem:
\begin{equation}
  E(\hat{S}(t + \Delta)| \hat{S}(t)) \neq \hat{S}(t) < \infty
\end{equation}
Należy więc odpowiednio zmodyfikować schemat z równanie (\ref{eq:HestonNoInterest}). W tym celu
Andersen proponuje, aby $K_0$ zastąpić nowym wyrażeniem $K_0^*$ zdefiniowanym w następujący 
sposób:
\begin{equation}
\label{eq:psi}
K_0^* =
            \begin{cases}
               - \frac{Ab^2a}{1-2Aa} + \frac{1}{2} \ln (1 - 2Aa) - (K_1 + \frac{1}{2} \Delta \gamma_1), &  \Psi \leq \Psi_c,\\
               - \ln (\frac{\beta (1-p)}{\beta - A} - (K_1 + \frac{1}{2} \Delta \gamma_1)), & \Psi > \Psi_c,\\
            \end{cases} 
\end{equation} 
Podstawiając powyższe wyrażenie do wzoru (\ref{eq:HestonNoInterest}) oraz ponownie uwzględniając
niezerową wartość stopy procentowej otrzymujemy:
\begin{equation}
\begin{aligned}
\label{eq:HestonInterestMartingale} 
\hat{S}(t + \Delta) &= \hat{S}(t) * exp(r \Delta\\ 
                    &+ K_0^* + K_1 \hat{v}(t) 
                    + K_2 \hat{v}(t+\Delta)
                    + \sqrt{K_3 \hat{v}(t) +  K_4 \hat{v}(t+\Delta)} \cdot Z)

\end{aligned}
\end{equation}
Powyższe równanie powoduje zdyskredytowane równanie dla aktywa bazowego jest martyngałem, a samą
wartość $K_0^*$ nazywamy \textbf{poprawką martyngałową} (\textit{ang. martingale correction}).


\section{Symulacja cen opcji w modelu Hestona}

Wprowadzając w poprzednim podrozdziale metody dyskretyzacji procesu stochastycznego mamy niezbędne 
narzędzia do przeprowadzenia symulacji Monte Carlo do wygenerowania ceny opcji w oparciu o model 
Hestona.
Wzór na wycenę europejskiej opcji \textit{call} na moment $T$ można przedstawić w następujący sposób:

\begin{equation}
  \hat{C}(T) = E \left[ (\hat{S}(T) - K)^{+}  \right]
\end{equation}
gdzie: $\hat{C}(T)$ oznacza aproksymację ceny opcji na moment $T$.


Gdy zdyskontujemy $\hat{C}(T)$ na moment zerowy otrzymamy wzór na moment zerowy:
\begin{equation}
  \hat{C}(0) = \frac{E \left[ (\hat{S}(T) - K)^{+} \right]}{e^{rT}} 
\end{equation}





%===========================================================================
%                       Model Hestona na przykładznie
%===========================================================================
\chapter{Wycena opcji na indeks S\&P500}\label{r:sp}


W poprzednich rozdziałach zostały przedstawione zostały formalne aspekty związane z modelami 
Blacka-Scholesa i Hestona, ten rozdział będzie poświęcony sprawdzeniu, jak w praktyce przedstawione 
modele się zachowują.
Jako instrument finansowy, na podstawie którego będziemy testować właściwości wymienionych modeli, 
wybrano indeks S\&P500. 

\section{Wycena opcji przy pomocy modelu Blacka-Scholesa}

Zanim przejdziemy do wyceny opcji  przy pomocy modelu Hestona oraz kalibracji
parametrów tego modelu, warto, w celach porównawczych zbadać wartość opcji 
wyznaczonej przy pomocy modelu Blacka-Scholesa. 


Dlatego też, porównamy otrzymaną wartość w modelu Blacka-Scholesa z ceną na rynku.
W celach porównawczych wybrano opcję o takiej samej cenie wykonania jak aktualna wartość indeksu 
S\&P500 o momencie wygaśnięcia przypadającym na dzień 16 grudnia 2016 roku. 
Rynkowa cena na tę opcję wynosi $13.08$ USD, natomiast otrzymana zgodnie z modelem Blacka-Scholesa 
wynosi $14.16$ USD.

Jak widać, ceny te nieznacznie różnią się wartością, jednak należy wziąć pod uwagę fakt, że nawet 
małe różnice w przyjętych parametrach mogą powodować różnice w cenie. 

Np. stopę wolną od ryzyka w pracy oszacowano na poziomie 3$\%$, zgodnie z rentownością 30-letnich 
obligacji wystawionych przez rząd Stanów Zjednoczonych. Niewykluczone, ze rentowność dla której cena 
opcji na rynku przyjmuje taką wartość jest nieznacznie inna.

Ponadto, jak zostało wspomniane w rozdziale dotyczącym wyceny opcji w modelu Blacka-Scholesa,
jedynym nieznanym parametrem w modelu jest zmienność, którą otrzymujemy podstawiając
dane rynkowe. 

Na podstawie danych wyliczono również płaszczyznę zmienności dla 
opcji na indeks S\&P500, co przedstawia rysunek nr \ref{fig:volatilitySurface}. 

\begin{figure}
  \centering
  \includegraphics[width=0.80\textwidth]{../output/figures/blackScholesVolSurface.pdf}
  \caption{Płaszczyzna zmienności implikowanej dla indeksu $S\&P$500}
  \label{fig:volatilitySurface}
\end{figure}

Dla opcji o bliskim terminie do wygaśnięcia bardzo dobrze jest widoczny
tak zwany uśmiech zmienności (\textit{ang. volatility smile}). Stwierdzenie uśmiech 
odnosi się do faktu, że dla opcji \textit{in-the-money} oraz \textit{out-the-money}
zmienność implikowana jest o wiele wyższa niż dla opcji \textit{at-the-money} (dla opcji o krótkim
terminie do wykupu).
Jest to zarazem kolejny dowód na to, że założenie o stałości zmienności w modelu Blacka-Scholesa jest 
rzeczywiście niespełnione.


\section{Kalibracja}

Zmienność implikowaną użytą w równaniu Blacka-Scholesa 
bardzo łatwo wyznaczyć mając dane podstawowe parametry 
opcji. Jednak, jak opisano w czwartym rozdziale, 
kalibracja (wyznaczenie optymalnych) parametrów modelu Hestona jest skomplikowana i jest
zadaniem optymalizacyjnym.  

Kalibracji dokonamy przy pomocy dostępnej w programie \textit{Matlab} funkcji \textit{lsqnonlin}, 
opisanej w rozdziale \ref{chap:chapterModelCalibration}.
Jednak, aby użyć tej funkcji potrzebujemy giełdowych danych wejściowych.


Rysunek \ref{fig:calibration} przedstawia, zrzutowane na wykresie, dane, które
zostały użyte w celu kalibracji modelu (jak widać, zostały użyte ceny 
opcji o 3 różnych terminach wygaśnięcia: 
6, 13 oraz 20 dni.)

\begin{figure}
  \centering
  \includegraphics[width=0.80\textwidth]{../output/figures/calibrationInput.pdf}
  \caption{Dane wejściowe do funkcji kalibrującej model Hestona do danych giełdowych}
  \label{fig:calibration}
\end{figure}

W wyniku kalibracji otrzymano następujące parametry:

\begin{itemize}
  \item $V(1) = 0.0369 $
  \item $\kappa = 20.1115$
  \item $\theta = 0.0000$
  \item $\sigma = 0.5000$
  \item $\rho = -0.9000$
\end{itemize}


Mając wyznaczone zadane parametry modelu, można przejść do wyceny opcji, stosując metodę Monte Carlo.


\section{Symulacja Monte Carlo ceny europejskiej opcji kupna na indeks S\&P500}

Po znalezieniu odpowiedniej wartości nieznanych paramentów modelu Hestona, można 
przejść do symulacji Monte Carlo wyznaczającej cenę opcji o zadanych właściwościach.

W tym rozdziale wycenimy opcję kupna o następujących właściwościach:
\begin{enumerate}
  \item cena początkowa aktywa bazowego = $207.93$
  \item cena wykupu opcji = $207.93$ 
  \item roczna stopa wolna od ryzyka = $0.03$
  \item początkowa zmienność =  $0.15$
  \item czas do wygaśnięcia opcji = 412 dni
\end{enumerate}
 
Na poniższym rysunku widać wynik symulacji ceny opcji dla kilkuset losowo wybranych przebiegów.
Z definicji Monte Carlo wynika, że poprawnym estymatorem ceny
opcji jest średnia średnia ze wszystkich przebiegów.
Na rysunku zaznaczono również poziomą linią wartość punktu startowego, tzn. wartość 
aktywa bazowego w momencie zerowym.

\begin{figure}
\centering
  \includegraphics[width=0.80\textwidth]{../chartHeston.png}
  \caption{Trajektorie procesu cen instrumentu bazowego}
  \label{fig:hestonAssetPaths}
\end{figure}


Z wykonania symulacji dla metody Hestona wynika, że średnia cena opcji z czasem do wygaśnięcia 
jednego roku wynosi $13.61$ USD, 
co jest znacznie bliższe wartości wycenianej przez rynek ($13.08$ USD) w porównaniu do modelu BS. 
Przypomnijmy, że dla modelu Blacka-Scholesa, cena ta wynosiła $14.16$ USD.


\section{Współczynniki greckie dla indeksu S\&P500}

Na koniec rozdziału przedstawimy zachowanie się modelu Hestona dla jednego, wybranego współczynnika 
greckiego, a mianowicie dla $\Theta$.

\textit{Theta}, jako współczynnik cen opcji w zależności od upływającego czasu:
\begin{equation}
  \Theta = - \frac{\delta V}{\delta T}
\end{equation}

Rysunek \ref{fig:hestonTimeToExpiry} przedstawia zachowanie się cen opcji wraz z rosnącym czasem do 
wygaśnięcia opcji. Dla pierwszego wykresu czas do wygaśnięcia wynosi pół roku, natomiast dla 
ostatniego wynosi 6 lat. 

Jak można zauważyć, wraz z spadającym czasem do wygaśnięcia maleje potencjalny rozrzut cen aktywa 
bazowego w momencie wygaśnięcia opcji.
Jest to zgodne z intuicją. Opcje, których cena jest zależna od zmienności instrumentu bazowego, 
w krótszym okresie czasu będą mniej warte od tych z dłuższym okresem do wygaśnięcia.

\begin{figure}
  \includegraphics[width=1.00\textwidth]{../output/figures/hestonTimeToExpiry.pdf}
  \caption{Cena instrumentu bazowego w modelu Hestona w zależności od czasu do wygaśnięcia opcji}
  \label{fig:hestonTimeToExpiry}
\end{figure}


%===========================================================================
%                             Zakończenie
%===========================================================================
\cleardoublepage
\phantomsection
\chapter*{Podsumowanie}\label{r:ending}
\addcontentsline{toc}{chapter}{Podsumowanie} \markboth{Finish}{}

Celem niniejszej pracy było porównanie modeli służących do wyceny
opcji oraz implementacja modelu Hestona, który wylicza wartość opcji biorąc
pod uwagę brak stałości w czasie zmienności, jednego z podstawowych parametrów
mającego wpływ na wycenę opcji. 

Pierwszym modelem służącym do wyceny opcji jest model Blacka-Scholesa, który jest
najprostszym modelem do wyceny opcji i porównano go do efektywności modelu 
Hestona. 

Model Hestona, który jest bardziej zaawansowany koncepcyjnie, jest jednocześnie 
bardziej skomplikowany obliczeniowo. Wynika to z faktu, że ma on kilka dodatkowych
parametrów, które należy wyznaczyć na podstawie informacji z rynku. Proces wyznaczania tych 
parametrów, nazwany procesem kalibracji, jest o wiele bardziej skomplikowany w przypadku 
modelu Hestona, ponieważ tutaj jest to zadanie optymalizacyjne, natomiast w przypadku modelu
Blacka-Scholesa jest to zadanie algebraiczne.

Szczegółowo opisano również, w jaki sposób należy zastosować symulację Monte Carlo do 
wygenerowania ceny opcji zgodnej z modelem Hestona. Krytycznym punktem okazał się być
proces dyskretyzacji procesu losowego. Przedstawiono dwa schematy: pierwszy - naiwny, nazwany
dyskretyzacją Eulera oraz drugi - bardziej dokładny, którego wynikiem było powstanie 
algorytmu Andersena. 

Z badań empirycznych jasno wynika, że założenie o stałości zmienności w czasie nie jest 
prawdziwe dla danych rzeczywistych. Ponadto, przeprowadzono wycenę opcji na indeks 
S\&P500 dla obydwu metod: modelu Blacka-Scholesa oraz modelu Hestona. 
W porównaniu do rynkowej ceny opcji o zadanych właściwościach, obydwie metody się 
sprawdzają, jednak większą dokładność osiągnął model Hestona.


Podsumowując, można stwierdzić, że model Hestona jest o wiele bardziej zaawansowanym
narzędziem do wyceny opcji niż model Blacka-Scholesa. Uwzględniając zróżnicowanie zmienności 
w czasie sprawia, że cena opcji jest bardziej dokładna. Cena jaką za to płacimy,
jest o wiele większe skomplikowanie modelu, zarówno w sferze koncepcyjnej, jak i 
implementacyjnej. Ze względu na konieczność wieloparametrowej kalibracji modelu, 
model ten jest o wiele bardziej czasochłonny obliczeniowo, niż chociażby model Blacka-Scholesa.

%===========================================================================
%                             Appendix - kody zrodlowe
%===========================================================================
\cleardoublepage
\phantomsection
\appendix

\chapter{Opis kodu źródłowego}

W tym rozdziale zostaną przedstawiona implementacja wybranych zagadnień przedstawionych w 
pracy magisterskiej. Kod źródłowy został napisany w dwóch językach programowania: 
\begin{enumerate}
  \item \textit{C++}
  \item \textit{Matlab}
\end{enumerate}
W tym pierwszym zaimplementowano następujące moduły:
\begin{itemize}
  \item model Hestona i różne sposoby jego dyskretyzacji
  \item model Blacka-Scholesa
  \item generator liczb z rozkładu normalnego
  \item symulację Monte Carlo dla modelu Hestona
\end{itemize}
Z kolei w języku \textit{Matlab} zaimplementowano kalibrację modelu Hestona do cen opcji pochodzących
z danych giełdowych.

Wszystkie zaimplementowane moduły zostały wykonane na maszynie o następujących parametrach:
\begin{enumerate}
  \item procesorze \textit{Intel Core i5, 2.6 GHz}
  \item pamięci \textit{8GB}
  \item systemie operacyjnym \textit{OS X El Capitan 10.11.3}
\end{enumerate}


\section{Model Hestona}
Na schemacie \ref{fig:currencyRisk} widać poszczególne klasy zaimplementowane w 
ramach modułu wyliczającego cenę opcji zgodną z modelem Hestona.
Klasą bazową, po której wszystkie inne dziedziczą jest klasa \textit{Heston}.
Jest ona bezpośrednią nadklasą dla klas definiujących różne podejścia do wyceny opcji zgodnej
z modelem Hestona:
\begin{enumerate}
  \item symulacji Monte Carlo (klasa \textit{HestonMC})
  \item wzoru zamkniętego (klasa \textit{HestonExact})
\end{enumerate}
Klasa \textit{HestonExact} zawiera w sobie implementację wzoru zamkniętego na cenę opcji,
Z kolei klasa \textit{HestonMC} definiuje jedynie interfejs jaki muszą spełniać klasy po niej 
dziedziczące.
Klasa \textit{HestonMC} jest nadklasą dla następujących klas:
\begin{enumerate}
  \item \textit{HestonAndersen} 
  \item \textit{HestonEuler} 
\end{enumerate}
Na schemacie \ref{fig:currencyRisk} widać również dodatkową klasę
\textit{HestonAndersenMartingale}. Jest to klasa implementująca 
poprawkę martyngałową dla klasy \textit{HestonAndersen}.


\begin{figure}
  \centering  
  \includegraphics[width=1.00\textwidth]{../output/diagramms/HestonDiagramm.pdf}
  \caption{Drzewo dziedziczenia dla modułu wyliczającego 
  cenę opcji wg różnych metodologii dla modelu Hestona.}\label{fig:currencyRisk}
\end{figure}
\cleardoublepage

\section{Interfejs abstrakcyjnych klas \textit{Heston} oraz \textit{HestonMC}}
W projekcie zostały zaimplementowane dwie abstrakcyjne klasy \textit{Heston} oraz \textit{HestonMC}.
Pierwsza z nich stanowi klasę bazową dla całej struktury drzewa dzedziczenia. 
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/heston/header/Heston.h}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\end{listing} 
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/heston/header/HestonMC.h}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\end{listing} 
Klasa (\textit{HestonMC})
jest klasą bazową dla klas wykonujących symulację Monte Carlo zgodnie z 
przyjętym schematem dyskretyzacji. Definuje ona dwie dodatkowe metody: \textit{simulateVolPath} oraz 
\textit{simulateSpotPath}.
\cleardoublepage




\subsection{Schemat Eulera}

W tym podrozdziale zostanie przedstawiony kod do wyceny opcji zgodnie z dyskretyzacją Eulera.
Na rysunku przedstawiono plik źródłowy klasy\textit{HestonEuler}. Jest ona rozszerzeniem klasy 
HestonMC, a więc udostępnia ona interfejs swoich nadklas. 



\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/heston/header/HestonEuler.h}
\caption{Plik nagłówkowy klasy \textit{HestonEuler}.}
\end{listing} 
Kod źródłowy \label{lst:Eulercpp} przedstawia z kolei implementację 2 powyższych metod:
\begin{enumerate}
  \item \textit{HestonEuler::simulateVolPath}
  \item \textit{HestonEuler::simulateSpotPath}
\end{enumerate}

\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/heston/src/HestonEuler.cpp}
\caption{Implementacja metod dla schematu Eulera.}
\label{lst:Eulercpp} 
\end{listing} 
\cleardoublepage




\subsection{Schemat Andersena}
W tym punkcie podana zostanie implementacja kolejnego schematu dyskretyzacji, schematu 
Andersena. Zostały podane dwa
pliki: jeden to plik nagłówkowy, a drugie z implementacją odpowiednich metod.
Klasa \textit{HestonAndersen} zawiera jedną dodatkową 
metodę:
\begin{itemize}
   \item \textit{HestonAndersen::modifiedExpInvCDF}
 \end{itemize} 
Jest to funkcja, która wylicza wartość odwrotnej dystrybuanty dla zmodyfikowanego rozkładu 
wykładniczego.
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonAndersen.h}
\caption{Schemat generowania trajektorii procesu aktywa bazowego wraz z poprawką
martyngałową}
\end{listing}
Podobnie jak dla dyskretyzacji Eulera definiujemy metody 
\begin{enumerate}
  \item \textit{HestonEuler::simulateVolPath},
  \item \textit{HestonEuler::simulateSpotPath}.
\end{enumerate}
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonAndersen.cpp}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}  
Metoda \textit{HestonEuler::simulateVolPath} oblicza trajektorię procesu zmienności, 
natomiast metoda \textit{HestonEuler::simulateSpotPath} wyznacza trajektorię procesu aktywa
bazowego.


\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonAndersen2.cpp}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}   

\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/ModifiedExpInvCDF.cpp}
\caption{Funkcja wyliczająca wartość odwrotnej dystrybuanty dla zmodyfikowanego rozkładu 
wykładniczego}
\end{listing}   
\cleardoublepage





\subsection{Schemat Andersena z poprawką Martyngałową}
W poprzednim punkcie zaimplementowano schemat Andersena. 
Niestety, proces aktywa bazowego w tym schemacie nie jest martyngałem.
Algorytm ten można jednak usprawnić tak, aby własność martyngału była spełniona.
Definiuję się zmienną $k_0^*$, która zastępuje zmienną $k_0$ następująco: 
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonAndersenMartingaleSpot.cpp}
\caption{Schemat generowania trajektorii procesu aktywa bazowego wraz z poprawką
martyngałową}
\end{listing}  

Klasa \textit{HestonAndersenMartingale} jest podlasą klasy \textit{HestonAndersen}, 
dlatego nie musimy implementować niektórych metod, jak np. metody wyliczają trajektorę procesu
wariancji. 
Klasa \textit{HestonAndersenMartingale} implementuje ponadto funckję do wyliczenia parametru $k_0^*$.
Metoda to nosi nazwę Poniżej podajemy implementację funkcji wyliczającej poprawkę martyngałową 
dla każdej punktu realizacji procesu aktywa bazowego.

\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonAndersenMartingaleMart.cpp}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}  
\cleardoublepage




\subsection{Wycena opcji przy pomocy wzoru zamkniętego}
W tym rozdziale zostaną przedstawione kody źródłowe dla alternatywnego podejścia 
wyceny opcji w modelu Hestona. Zamiast polegać na niedeterministycznej metodzie
Monte Carlo, zostanie użyty wzór zamknięty. Plik nagłówkowy dla tej klasy
został przedstawiony poniżej.
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonExact.h}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}  
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonExact1.cpp}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}  
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/HestonExact2.cpp}
\caption{Metoda wyliczająca poprawkę martyngałową}
\end{listing}  


%===========================================================================
%                             Polar generator
%===========================================================================
\cleardoublepage
\section{Generator liczb z rozkładu normalnego}
Przedstawiony poniżej kod źródłowy przedstawia plik nagłówkowy definiujący interfejs 
generatora liczb losowych z rozkładu normalnego. 
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/random/PolarGenerator.h}
\caption{Plik nagłówkowy klasy \textit{PolarGenerator}}
\end{listing} 
Klasa ta została utworzona zgodnie z kreacyjnym wzorcem projektowym \textit{singleton}. 
Głowną zaletą tego wzorca jest to, że pozwalamy na utworzenie tylko jednego obiektu danej 
klasy, co jest istotne w przypadku implementacji konstruktora klasy definiującej
generator liczb pseudolosowych.
Implementacja wzorca została wykonana zgodnie ze schematem podanym przez Meyersa \cite{Meyers}, 
która jest bezpieczna w środowisku wielowątkowym (\textit{ang. thread-safe}).
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/random/PolarGenerator.cpp}
\caption{Implementacja interfejsu klasy \textit{PolarGenerator}}
\label{lst:PolarGeneratorcpp}
\end{listing} 
Kod źródłowy nr \ref{lst:PolarGeneratorcpp} przedstawia implementację konstruktora oraz metody
generującej liczby z rozkładu normalnego \textit{genNorm()}.


%===========================================================================
%                             Model Blacka-Scholesa
%===========================================================================
\cleardoublepage
\section{Model Blacka-Scholesa}
Kod źródłowy nr \ref{lst:BlackScholesh} przedstawia plik nagłówkowy dla implementacji 
modelu Blacka-Scholesa. Implementacja ta jest użyta do porównania wartości opcji dla 
modelu Blacka-Scholesa i modelu Hestona.
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/bs/MCBlackScholes.h}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\label{lst:BlackScholesh}
\end{listing} 
Kod źródłowy \ref{lst:BlackScholescpp} przedstawia konstruktor klasy \textit{MCBlackScholes} 
oraz implementację metody \textit{simulate}.
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/bs/MCBlackScholes.cpp}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\label{lst:BlackScholescpp}
\end{listing} 


%===========================================================================
%                         Symulacja Monte Carlo
%===========================================================================
\cleardoublepage
\section{Symulacje Monte Carlo}
Kod źródłowy \ref{lst:MonteCarloh} przedstawia plik nagłówkowy dla implementacji symulacji 
Monte Carlo dla modelu Hestona. Plik definiuje interfejs jaki musi spełniać
implementacja symulacji Monte Carlo. Najważniejszą publiczną metoda jest metoda \textit{simulate}, 
dla której jako parametr przekazujemy odpowiedni schemat dyskretyzacji modelu Hestona 
oraz opcję do wyceny. 
Ponadto zdefiniowany jest konstruktor klasy, który jako parametry przyjmuje dwie zmienne:
\textit{simulationTrials} oraz \textit{timeSteps}.
Pierwsza ze zmiennych definiuje ile razy wykonujemy pojedyncza symulacje, natomiast druga 
definiuje liczbę kroków w pojedynczej symulacji. Innymi słowy, czas wygaśnięcia opcji 
podzielny przez liczbę kroków definiuje nam jednostkowy przyrost czasu.
\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/mc/MonteCarloSimulation.h}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\label{lst:MonteCarloh}
\end{listing} 
Kod źródłowy nr \ref{lst:MonteCarlocpp} przedstawia główną funkcję użytą w tym celu. 
Zastosowano w niej prostą metodę Monte Carlo wraz ze schematem dyskretyzacji Eulera. 
Parametrami dla funkcji \textit{simulateHeston} są dwa wektory, pierwszy zawierający
parametry modelu Hestona, natomiast drugi parametry opcji, której cenę chcemy wyznaczyć. 
Główną częścią pokazanego algorytmu jest pętla w liniach 20-24, która stanowi faktyczną symulację
Monte-Carlo. Najpierw generujemy w niej skorelowane ciągi losowe mające rozkład normalny, 
a następnie na ich podstawie generujemy kolejno trajektorię zmienności oraz trajektorię aktywa
bazowego. W linii 24 bierzemy wartość aktywa bazowego w momencie $T$ i na tej podstawie obliczamy dla
tej wartości kwotę wypłaty opcji. Aby otrzymać wartość opcji, musimy wziąć średnią z wypłat i
zdyskontować ją na moment zerowy, co jest widoczne w liniach 27-28.

\begin{listing}[H]
\label{lst:MCHeston} 
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../output/listings/MonteCarloSimulation.cpp}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\label{lst:MonteCarlocpp}
\end{listing}  

%===========================================================================
%                         Kalibracja do danych rynkowych
%===========================================================================
\cleardoublepage
\section{Kalibracja do danych rynkowych}
Kod źródłowy \ref{lst:MonteCarloh} przedstawia główny program wykonujący
kalibrację do danych rynkowych.

\begin{listing}[H]
\inputminted[mathescape, linenos, numbersep=5pt, bgcolor=bg, frame=lines, framesep=2mm]{cpp}
{../src/HestonCPP/src/main/cpp/mc/MonteCarloSimulation.h}
\caption{Metoda Monte Carlo dla modelu Hestona  \cite{HallsMoore}}
\label{lst:MonteCarloh}
\end{listing}




%===========================================================================
%                             Appendix wyniki numeryczne
%===========================================================================
\cleardoublepage
\phantomsection
\appendix

\chapter{Wyniki przeprowadzonych symulacji}

Poniższy rozdział przedstawia wyniki przedprowadzonych symulacji.

\begin{table}[htbp]
\centering
\begin{tabular}{lrrrrr}
\toprule
{} &  500 &   6.74973 &   6.80647 &   6.81121 &   8.44991 \\
\midrule
0  &  250 &   6.67124 &   6.85153 &   6.81647 &   8.44991 \\
1  &  200 &   6.83865 &   6.77817 &   6.82660 &   8.44991 \\
2  &  150 &   6.63345 &   6.84858 &   6.85428 &   8.44991 \\
3  &  100 &   6.73396 &   6.77222 &   6.81849 &   8.44991 \\
4  &   50 &   6.61328 &   6.57659 &   6.60319 &   8.44991 \\
5  &   30 &   6.68642 &   6.72968 &   6.74412 &   8.44991 \\
6  &   10 &   6.35001 &   6.47263 &   6.24196 &   8.44991 \\
7  &  500 &  36.17590 &  36.11660 &  33.89330 &  35.33290 \\
8  &  250 &  35.60600 &  34.51300 &  35.79700 &  35.33290 \\
9  &  200 &  34.00110 &  34.71120 &  34.55620 &  35.33290 \\
10 &  150 &  34.26050 &  35.35470 &  35.29990 &  35.33290 \\
11 &  100 &  34.24080 &  34.68710 &  35.29590 &  35.33290 \\
12 &   50 &  33.00240 &  34.51250 &  34.52500 &  35.33290 \\
13 &   30 &  35.17320 &  34.87670 &  34.33390 &  35.33290 \\
14 &   10 &  32.81370 &  32.36760 &  31.82070 &  35.33290 \\
15 &  500 &   8.07707 &   8.03216 &   8.00030 &   8.04498 \\
16 &  250 &   8.05999 &   8.04874 &   8.10905 &   8.04498 \\
17 &  200 &   8.06357 &   7.97690 &   7.93545 &   8.04498 \\
18 &  150 &   8.03599 &   8.02978 &   8.07944 &   8.04498 \\
19 &  100 &   7.97958 &   7.84094 &   7.85451 &   8.04498 \\
20 &   50 &   7.96275 &   7.80595 &   7.88293 &   8.04498 \\
21 &   30 &   7.99528 &   7.41098 &   7.66893 &   8.04498 \\
22 &   10 &   8.52388 &   3.86428 &   7.05175 &   8.04498 \\
\bottomrule
\end{tabular}
\caption{caption}
\label{tab:ref}
\end{table}


%===========================================================================
%                             Listingi
%===========================================================================
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Lista rysunków}{\listoffigures}
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Lista tabel}{\listoftables}
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Lista kodów źródłowych}{\listoflistings}
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Lista algorytmów}{\listofalgorithms}
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Bibliografia}{\printbibliography}

\end{document} 